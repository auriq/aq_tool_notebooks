{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDB Walk Through with Amazon Product Dataset\n",
    "\n",
    "## Intro\n",
    "\n",
    "In this notebook we will be looking at a simple use case example of udb, table, vector and variables to organize the famous [Amazon Product Review Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html), which is publically available on aws s3 bucket. \n",
    "\n",
    "It is a collection of amazon customer reviews, left between 1995 and 2015, contains millions of data points. \n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "In order to go through this notebook, we'll assume that you're somewhat familar with\n",
    "* bash and linux commands/scripting\n",
    "* Essentia and aq_tool command\n",
    "* little bit of UDB, aq_udb command\n",
    "\n",
    "Resources below are available for reference if needed, \n",
    "* [Essentia Playground Home](../README.ipynb)\n",
    "* [AuriQ Knowledge Base](http://auriq.com/knowledge-base/) where documentations and tutorials are available. \n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Before getting our hands dirty with the data, we'll take a look at the columns and information contained in the data. \n",
    "It has 15 columns total, some of which are important for this tutorial, such as followings.\n",
    "\n",
    "* **customer_id**: int - unique identifier for a customer who left review(s)\n",
    "* **product_parent**: int - unique identifier for a product. This can be used to merge same product across different marketplace.\n",
    "* **review_id**: string - unique identifier for a review. \n",
    "* **star_rating**: int - star rating, ranging from 1 to 5. \n",
    "* **verified_purchase**: string - whether or not the review is based on verified purchase. String value of \"Y\" for verified, or \"N\" for otherwise.\n",
    "* **review_date**: string - string value describing the year, month and date of the review, in format of `2014-08-01`.\n",
    "\n",
    "## What's UDB?\n",
    "If you're already familiar with these concepts, feel free to skip to next section (GOAL). \n",
    "\n",
    "What were udb (User Data Base)? It is a in-memory database that stores data using key-value type data structure. \n",
    "There are 3 main components, and couple attributes to keep in mind.\n",
    "\n",
    "### Components\n",
    "\n",
    "\n",
    "* **Database** - database itself. Contains the following 3 components, and must have a specified primary key.\n",
    "* **Table** - Analogous to SQL table with primary key column, except that foregin key does not exist.\n",
    "* **Vector** - A container to store single record / row of data. Each vector(row) stores a information that is associated with one unique primary key in the database (can be a single customer, or product in amazon dataset for instance). *Also acts as \"strainer\" for data. More on this later*\n",
    "* **Variable** - as the name suggest, this stores values temporarly. Not really a datatype, but comes in handy when performing complex calculations. \n",
    "\n",
    "### Attributes\n",
    "UDB attributes are very powerful. You can assgin one of the following attributes to each column of table / vector. When the data flows into table/vector's columns with these attributes, each performs / stores the followings.\n",
    "\n",
    "* `pkey`: primary hash key, must be string type\n",
    "* `tkey`: integer sorting key, used to sort records within each primary keys.\n",
    "* `+key`: [long discription available](http://www.auriq.com/documentation/source/reference/manpages/udb.spec.html)\n",
    "* `+first`: keep the first vaule when importing data\n",
    "* `+last`: keep the last value when importing data\n",
    "* `+add`: add incoming value to existing value, can be used to calculate cumulative sum across records\n",
    "* `+bor`: Bitwise-OR numeric values\n",
    "* `+min`: Take the smallest value when importing\n",
    "* `+max`: Take the largest value when importing\n",
    "* `+nozero`: Ignore values of 0 or an empty string\n",
    "\n",
    "\n",
    "## Goal\n",
    "\n",
    "The final goal of this tutorial is to import the data into udb, in a way that is easy to manage and analyze later. Concretely, we will create the following databases, tables and vectors.\n",
    "\n",
    "### Database: Amazon\n",
    "This database contains a table and a vector, which are \n",
    "* Table: reviews - keeps all of the original review dataset. \n",
    "* vector: customer - contains summary of each customer's information, such as numbers of reviews each customer left, average star rating of each customer, numbers of helpful votes. \n",
    "\n",
    "**Put shemas here**\n",
    "\n",
    "### Database: Products\n",
    "This database only contains one vector\n",
    "* vector: product - summarizes the information for each product, such as numbers of reviews left, average star ratings, etc. \n",
    "\n",
    "**Schema**\n",
    "\n",
    "## Steps\n",
    "The whole project can be divided up into the following steps. \n",
    "1. define, and crate data schemas on udb, and start udb server\n",
    "2. Stream the data from datastore, process some of the columns, and fill up `reviews` table. \n",
    "\n",
    "## 1. definition \n",
    "We'll select datastore, create category, and define data schemas for udb. Finally start the udb server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 230M Nov 24 2017     /tsv/amazon_reviews_multilingual_DE_v1_00.tsv.gz\n",
      "  67M Nov 24 2017     /tsv/amazon_reviews_multilingual_FR_v1_00.tsv.gz\n",
      "  90M Nov 24 2017     /tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\n",
      " 333M Nov 24 2017     /tsv/amazon_reviews_multilingual_UK_v1_00.tsv.gz\n",
      " 1.4G Nov 24 2017     /tsv/amazon_reviews_multilingual_US_v1_00.tsv.gz\n",
      "2020-03-05 23:48:54 ip-10-10-1-36.ec2.internal ess[12960]: !!!Warning!!! Category danish_reviews already defined. Ignoring command.\n"
     ]
    }
   ],
   "source": [
    "# choosing the public s3 bucket that stores amazon review dataset as datastore\n",
    "ess select s3://amazon-reviews-pds\n",
    "# taking a look at what's inside of the bucket. \n",
    "ess ls /tsv/amazon_reviews_multi*.tsv.gz\n",
    "\n",
    "# create a category, only including Danish reviews to keep data size small.\n",
    "ess category add danish_reviews \"/tsv/amazon_reviews_multilingual_DE_v1_00.tsv.gz\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        danish_reviews\n",
      "Pattern:     /tsv/amazon_reviews_multilingual_DE_v1_00.tsv.gz\n",
      "Exclude:     None\n",
      "Date Format: auto\n",
      "Date Regex:  \n",
      "Archive:     \n",
      "Delimiter:   Tab\n",
      "# of files:  1\n",
      "Total size:  230.7MB\n",
      "File range:  1970-01-01 - 1970-01-01\n",
      "# columns:   15\n",
      "Column Spec: S:marketplace I:customer_id S:review_id S:product_id I:product_parent S:product_title S:product_category I:star_rating I:helpful_votes I:total_votes S:vine S:verified_purchase S,trm:review_headline S,esc:review_body S:review_date\n",
      "Pkey: \n",
      "Schema: S:marketplace I:customer_id S:review_id S:product_id I:product_parent S:product_title S:product_category I:star_rating I:helpful_votes I:total_votes S:vine S:verified_purchase S,trm:review_headline S,esc:review_body S:review_date\n",
      "Preprocess:  \n",
      "usecache:    False\n",
      "Comment:    \n",
      "\n",
      "First few lines:\n",
      "marketplace\tcustomer_id\treview_id\tproduct_id\tproduct_parent\tproduct_title\tproduct_category\tstar_rating\thelpful_votes\ttotal_votes\tvine\tverified_purchase\treview_headline\treview_body\treview_date\n",
      "DE\t10133\tRVOG49N0H1FB6\tB004TACMZ8\t569741360\tBosch GMS120 Ortungsgerät digital multi-Scanner\tHome Improvement\t5\t0\t0\tN\tY\tSuper\tDelivery took a little bit more then i expected(2 days more) but package was in good condition and the device i fully functional.\t2014-08-01\n",
      "DE\t19612\tRNCMD6OLTP4HM\t1846071224\t785505948\tThe Wheels On The Bus: Favourite Nursery Rhymes (BBC Audio Children's)\tBooks\t5\t1\t1\tN\tY\tGreat compilation\tWe enjoy listening to the song as preparation for our baby. Some of the songs were quite new even for us. We hope our baby will enjoy the songs too as much as we do.\t2014-12-04\n",
      "DE\t19612\tR4AUOBI8YC0R8\t0375851569\t516548029\tDr. Seuss's  Beginner Book Collection\tBooks\t5\t0\t0\tN\tY\tGreat Collection\tVery great compilation. Interesting story and rhymes even for adults. The tongue twister is amazing. This complete my collection of Dr. Seuss's.\t2014-12-04\n",
      "DE\t19677\tR1VSHIJ1RHIBTE\tB0060SVG54\t302116447\tZwei an einem Tag\tVideo DVD\t5\t0\t0\tN\tY\tGuter Verfilmung\tDen Film habe ich bereits vor lesen des Buches gesehen und war begeistert. Die Geschichte kann jeder nachvollziehen und mitfühlen.<br />Wer hatte nicht einmal diesen eine &#34;besten&#34; Freund?!<br />Man kann ihn allein genießen, genauso gut aber auch mit dem Partner oder zu einem schönen Mädelsabend, er passt einfach immer und bei fast jeder Altersgruppe.\t2015-07-16\n"
     ]
    }
   ],
   "source": [
    "ess summary danish_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what the data and its schema looks like, we can create and start udb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip-10-10-1-36: Starting udbd-10010.\n",
      "ip-10-10-1-36: udbd-10010 (13405) started.\n"
     ]
    }
   ],
   "source": [
    "# This section will create a database and its schemas\n",
    "\n",
    "# first make sure there's no existing udb / schemas. \n",
    "ess server reset\n",
    "\n",
    "# create database \"amazon\", on port 0. \n",
    "# Everything that'll be created after this will be inside of \"amazon\" database. (except ohter database)\n",
    "ess create database amazon --port 0\n",
    "\n",
    "# create tables and vectors, with column specs in amazon db\n",
    "ess create table reviews S:marketplace I,pkey:customer_id I:u_time S:review_id S:product_id I:product_parent S:product_title S:product_category I:star_rating I:helpful_votes I:total_votes S:vine S:verified_purchase S:review_headline S:review_body S:review_date I:year I:month I:day\n",
    "ess create vector customer I,pkey:customer_id I,+add:num_review I,+add:helpful_votes I,+add:total_votes I,+max:max_star I,+min:min_star I,+add:sum_star I,+add:num_verified_purchase\n",
    "\n",
    "# create products db, and product vector inside\n",
    "ess create database products\n",
    "ess create vector product I,pkey:product_parent I,+add:num_review I,+add:num_verified_purchase I,+min:min_star I,+add:sum_star\n",
    "\n",
    "# this will start the udbd server. \n",
    "ess udbd start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closer Look at the UDB Schemas\n",
    "\n",
    "Let's take a look at each schema to understand what they do. \n",
    "We will only focus on significant ones that will be used or target of a data processing later. \n",
    "\n",
    "\n",
    "#### `Amazon:review` table\n",
    "* `I,pkey:customer_id`: primary key to hash on.\n",
    "* `I:u_time` \n",
    "* `S:review_id` \n",
    "* `I:product_parent`\n",
    "* `I:star_rating` \n",
    "* `I:helpful_votes` & `I:total_votes` \n",
    "* `S:verified_purchase` \n",
    "* `S:review_date` \n",
    "* `I:year`, `I:month`, and `I:day`\n",
    "\n",
    "#### `Amazon:customer` vector\n",
    "\n",
    "This vector is used to summarize each customer's data.\n",
    "Single vector stores info about one customer (`customer_id`), therefore there are same numbers of vectors as number of unique `customer_id` present in the data. \n",
    "\n",
    "* `I,pkey:customer_id`: primary key, corresponds to unique customers in the dataset.  \n",
    "* `I,+add:num_review`: `+add` is used to keep adding values that go through this column. Used to get cumulative sum of values on `num_review` column across records, for each `customer_id`. \n",
    "* `I,+add:helpful_votes` & `I,+add:total_votes`: get the total numbers of each votes per each `customer_id`. \n",
    "* `I,+max:max_star`, and `I,+min:min_star`: `+max` and `+min` only keeps max and min value across the records for each primary key (`customer_id`). Used to get min and max star_rating that each user left.\n",
    "* `I,+add:sum_star`: used to get cumulative sum of star_rating across records for each `customer_id`. \n",
    "* `I,+add:num_verified_purchase`:used to count numbers of verified purchases made by each `customer_id`. Used in accordance with `-if -else` options in `aq_pp` command, which will be covered later. \n",
    "\n",
    "#### `Products:product` vector\n",
    "Similary, each of this vector contains records for each unique product present in the dataset. \n",
    "Same / similar schema is used to collect data for each product, by using different primary key.\n",
    "\n",
    "* `I,pkey:product_parent`: primary key to identify a product\n",
    "* `I,+add:num_review`: used to count numbers of records (reviews) per each product\n",
    "* `I,+add:num_verified_purchase`: to count number of verified purchase. Used with conditional statement in `aq_pp`.\n",
    "* `I,+min:min_star`: keep minimum star rating value for each product.\n",
    "* `I,+add:sum_star`: calculate the cumulative sum of star rating left on each product.\n",
    "\n",
    "\n",
    "### Streaming Data \n",
    "\n",
    "Now we have the servers running with necessary schemas, we'll stream our data from datastore (s3) to the udb tables and vectors, while processing the data on the fly. \n",
    "\n",
    "While processing, the data will go through the following processing using `aq_pp` command,\n",
    "\n",
    "* convert `review_date` column's string value into unix time, and store it in `u_time` integer column.\n",
    "* extract year, month and date from `review_date` column, and remap them onto individual new columns. --> Done by `-mapf` and `-mapc` options.\n",
    "* create new `sum_star`, `min_star` and `max_star` columns from `star_rating` column, and stream them into `product` and `customer` vectors. \n",
    "* create and assign `num_review` column value of 1, which will be used to count the numbers of records (reviews) per product / customers, while they're streamed into the 2 vectors. \n",
    "* create `num_verified_purchase` column, and conditionally fill it's value using `-if -else` option. \n",
    "\n",
    "Finally `-imp` option was used to specify the table and vectors to import/stream the data into. \n",
    "\n",
    "**Note:**: In order for a column of data to be imported, \n",
    "the column spec of the data (from `aq_pp`) needs to **match with the column spec of the table/vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-06 00:56:26 ip-10-10-1-36.ec2.internal ess[13427]: !!!Warning!!! Multiple warnings.  See task.log for more details\n"
     ]
    }
   ],
   "source": [
    "# set column spec\n",
    "COL=\"S:marketplace I:customer_id S:review_id S:product_id I:product_parent S:product_title S:product_category I:star_rating I:helpful_votes I:total_votes S:vine S:verified_purchase S,trm:review_headline S,esc:review_body S:review_date\"\n",
    "AMT=\"1000\"\n",
    "\n",
    "# stream, process and fill up udb table and product vector. \n",
    "ess stream danish_reviews \"*\" \"*\" \\\n",
    "    \"aq_pp -f,eok,tsv - -d $COL \\\n",
    "    -eval I:u_time 'DateToTime(review_date, \\\"%Y.%m.%d\\\")' \\\n",
    "    -mapf review_date '%%YEAR%%-%%MONTH%%-%%DATE%%' \\\n",
    "    -mapc s:s_year '%%YEAR%%' -mapc s:s_month '%%MONTH%%' -mapc s:s_day '%%DATE%%' \\\n",
    "    -eval i:year 'ToI(s_year)' -eval i:month 'ToI(s_month)' -eval i:day 'ToI(s_day)' \\\n",
    "    -eval I:sum_star 'star_rating' -eval I:min_star 'star_rating' -eval I:max_star 'star_rating' -eval I:num_review 1 \\\n",
    "    -if -filt 'verified_purchase == \\\"Y\\\"' -eval I:num_verified_purchase '1' -else -eval num_verified_purchase '0' -endif \\\n",
    "    -imp,ddef,seg=1/$AMT amazon:reviews -imp,seg=1/$AMT amazon:customer -imp,seg=1/$AMT products:product\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table and vector are filled up, so let's take a look using `aq_udb` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"marketplace\",\"customer_id\",\"u_time\",\"review_id\",\"product_id\",\"product_parent\",\"product_title\",\"product_category\",\"star_rating\",\"helpful_votes\",\"total_votes\",\"vine\",\"verified_purchase\",\"review_headline\",\"review_body\",\"review_date\",\"year\",\"month\",\"day\"\n",
      "\"DE\",3859831,1420156800,\"RU66BVNON80FI\",\"B000024EXY\",202640400,\"Seconds Out\",\"Music\",5,1,3,\"N\",\"Y\",\"einfach klasse\",\"Ich h&ouml;re Genesis schon seit Anfang der 80'er. Nach dem Abgang des genialen, aber auch, f&uuml;r meinen Geschmack etwas zu abgedrehten Peter Gabriel, hatten Genesis m.E. ihre beste Zeit. Ich habe mir endlich auch die &#34;And than they where three&#34; gekauft. Unbedingt empfehlen kann ich auch &#34;A Trick of the Tail&#34;, &#34;Wind and Wuthering&#34; und nat&uuml;rlich &#34;The Lamb lies down on Broadway&#34;!!\",\"2015-01-02\",2015,1,2\n",
      "\"DE\",3965250,1433462400,\"R3OI6RJRW2ZPVQ\",\"B00ERLTDCO\",921065352,\"Desperate Housewives - Staffel 8\",\"Digital_Video_Download\",1,5,11,\"N\",\"N\",\"Stellungnahme !!!!\",\"Hi Amazon....!!!!  Wie wärs mal mit ner Stellungnahme zum desperate housewives &#34;fall&#34; ??!!! Überhaupt zu den kosten, die plötzlich anfallen\",\"2015-06-05\",2015,6,5\n",
      "\"customer_id\",\"num_review\",\"helpful_votes\",\"total_votes\",\"max_star\",\"min_star\",\"sum_star\",\"num_verified_purchase\"\n",
      "3859831,1,1,3,5,5,5,1\n",
      "3965250,1,5,11,1,1,1,0\n",
      "4386007,2,2,3,4,2,6,1\n",
      "5539266,1,0,0,5,5,5,1\n",
      "6680431,1,0,0,5,5,5,1\n",
      "\"product_parent\",\"num_review\",\"num_verified_purchase\",\"min_star\",\"sum_star\"\n",
      "404311150,14,6,2,62\n",
      "650084900,39,34,2,172\n",
      "123077453,3,2,3,13\n",
      "908800452,15,15,1,56\n",
      "888749714,99,16,1,241\n"
     ]
    }
   ],
   "source": [
    "# export data from the tables and vectors, top few results only\n",
    "# table \n",
    "aq_udb -exp amazon:reviews -top 2\n",
    "# vectors\n",
    "aq_udb -exp amazon:customer -top 5\n",
    "aq_udb -exp products:product -top 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did this happen??\n",
    "\n",
    "This section will explain how the 2 vectors and their attributes were used to calculate the values alongside with `aq_pp` command. \n",
    "\n",
    "Let's start with taking a look at the part of `aq_pp` command. \n",
    "\n",
    "\n",
    "### Star Ratings\n",
    "This was done in some of the `-eval` options. Below is the chunk of code. \n",
    "\n",
    "```bash\n",
    "aq_pp -f, .... \n",
    "-eval I:sum_star 'star_rating' -eval I:min_star 'star_rating' -eval I:max_star 'star_rating' ...\n",
    "```\n",
    "We're simply creating 3 new columns, all of them contains same values from `star_rating` column. All three columns' data are streamed into the columns with same names on the 2 vectors, and keeps/calculate value from the data.\n",
    "\n",
    "For each primary keys (`customer_id` or `product_parent`),\n",
    "* `I,+min:min_star`: keeps only the minimum star_rating value.\n",
    "* `I,+max:max_star`: same, but only max value.\n",
    "* `I,+add:sum_star`: adds up all of the star_rating values across the records.\n",
    "\n",
    "### Number of Reviews\n",
    "\n",
    "How are the numbers of reviews for each customer/product calculated? \n",
    "\n",
    "Remember that each unique value of `review_id` represent a unique review entry in the dataset. Because there are no duplicates of `review_id` across this entire dataset, we can assume that **each row of the dataset represent unique review entry** also. <br>\n",
    "Hence, we can get numbers of reviews per customer/product by counting numbers of rows per customer/product. \n",
    "\n",
    "This is done in one of the `-eval` option also, like\n",
    "```bash\n",
    "aq_pp -f ... \n",
    "-eval I:num_review 1 ... \n",
    "```\n",
    "where every value for the new `num_review` column is equal to 1. \n",
    "This data is streamed into the 2 vectors' column with same name, which has the attribute of `+add` (`I,+add:num_review`). This attribute gives cumulative sum of the values. \n",
    "\n",
    "### Number of Varified Purchases\n",
    "\n",
    "The original column was represented by string, \"Y\" for verified, and \"N\" for not verified. \n",
    "We'd like to count the number of \"Y\" for each customer/product, and store it in the vectors. \n",
    "\n",
    "First, each string value was mapped to a new column called `num_verified_purchase`, \n",
    "* \"Y\" --> 1\n",
    "* \"N\" --> 0\n",
    "\n",
    "This was done by using conditional statement block in `aq_pp`, which is\n",
    "\n",
    "```bash\n",
    "aq_pp -f ... \n",
    "-if -filt 'verified_purchase == \\\"Y\\\"' -eval I:num_verified_purchase '1' -else -eval num_verified_purchase '0' -endif ...\n",
    "```\n",
    "\n",
    "Finally, the value from this column was summed up for each customer/product as the data go through the vectors in the column `I,+add:num_verified_purchase`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn things off after using\n",
    "ess server reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
