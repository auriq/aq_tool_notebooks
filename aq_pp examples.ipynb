{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aq_pp command examples\n",
    "\n",
    "In this notebook, we'll go over common usage examples of the data preprocessing command, `aq_pp`. We'll start from very basic, and work our way up to advanced examples.\n",
    "\n",
    "Before going over this notebook, make sure you're faimilar with \n",
    "\n",
    "* Bash commands\n",
    "* Regular Expression\n",
    "* aq_input / input-spec \n",
    "\n",
    "We won't go over input, column and output spec on this notebook. They can be found on \n",
    "- [this notebook](aq_input.ipynb).\n",
    "- [aq_output notebook](aq_output.ipynb)\n",
    " \n",
    "\n",
    "Also have the [aq_pp documentation](http://auriq.com/documentation/source/reference/manpages/aq_pp.html) ready on your side, so you can refer to the details of each options as you go over this sample.\n",
    "\n",
    "## ToS\n",
    "\n",
    "## Basic Options\n",
    "\n",
    "### Evaluation (Better wording?)\n",
    "\n",
    "- `-eval`\n",
    "- `-var`\n",
    "\n",
    "### Output Options\n",
    "- `-c`\n",
    "- `-o`\n",
    "- `-ovar`\n",
    "\n",
    "### Combining Datasets\n",
    "- `-cat`\n",
    "- `-cmb`\n",
    "- `-sub`\n",
    "\n",
    "### Filtering\n",
    "- `-grep`\n",
    "- `-filt`\n",
    "\n",
    "\n",
    "### String Manipulation\n",
    "- `-mapf ... -mapc`\n",
    "- `-map`\n",
    "\n",
    "\n",
    "### Conditionals\n",
    "- `-if`\n",
    "- `-elif`\n",
    "- `-else`\n",
    "- `-endif`\n",
    "\n",
    "\n",
    "### Variable usage\n",
    "### Advanced Options\n",
    "- `-kenc`\n",
    "- `-kdec`\n",
    "- `-pmod`\n",
    "- `-imp`\n",
    "- `-exp`(this belongs to input spec, so should be in [aq_input notebook](aq_input.ipynb)?\n",
    "### Buildin Variables\n",
    "- `Random`\n",
    "- `RowNum`\n",
    "- `CurSec`\n",
    "- `CurUSec`\n",
    "\n",
    "\n",
    "## Basic Options\n",
    "we'll start with basic options for data wrangling. Let's take a look at them by objectives.\n",
    "\n",
    "### Evalutation\n",
    "\n",
    "This section explores 2 options, \n",
    "- `-eval`: evaluates give expression, and store the result in exsiting or new column.\n",
    "- `-var`: create a new variable and initialize it's value. \n",
    "\n",
    "These 2 options are essential for manipulating and performing calculations on it. \n",
    "\n",
    "#### [-eval](http://auriq.com/documentation/source/reference/manpages/aq_pp.html#eval)\n",
    "\n",
    "Basic syntax for this option is\n",
    "```bash\n",
    "aq-pp ... -eval ColSpec|ColName Expr\n",
    "```\n",
    "where\n",
    "- `ColSpec`: new column's column spec to assign the result\n",
    "- `ColName`: existing column name to assign the result\n",
    "- `Expr`: expression to be evaluated.\n",
    "\n",
    "#### Data\n",
    "\n",
    "[Ramen Ratings Dataset](https://www.kaggle.com/residentmario/ramen-ratings) from kaggle will be used in this sample, which contains ratings of 2500 ramen products. \n",
    "\n",
    "Review|Brand|Variety|Style|Country|Stars\n",
    "---|---|---|---|---|---|\n",
    "2580|New Touch|T's Restaurant Tantanmen|Cup|Japan|3.75\n",
    "2579|Just Way|Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles|Pack|Taiwan|1\n",
    "2578|Nissin|Cup Noodles Chicken Vegetable|Cup|USA|2.25\n",
    "2577|Wei Lih|GGE Ramen Snack Tomato Flavor|Pack|Taiwan|2.75\n",
    "2576|Ching's Secret|Singapore Curry|Pack|India|3.75\n",
    "2575|Samyang Foods|Kimchi song Song Ramen|Pack|South Korea|4.75\n",
    "2574|Acecook|Spice Deli Tantan Men With Cilantro|Cup|Japan|4\n",
    "2573|Ikeda Shoku|Nabeyaki Kitsune Udon|Tray|Japan|3.75\n",
    "2572|Ripe'n'Dry|Hokkaido Soy Sauce Ramen|Pack|Japan|0.25\n",
    "2571|KOKA|The Original Spicy Stir-Fried Noodles|Pack|Singapore|2.5\n",
    "\n",
    "Here are its' columns and data types.\n",
    "- `int: Review #`: review id number, the more recent the review is, the bigger the number is\n",
    "- `str: Brand`: brand / manufacture of the product\n",
    "- `str: Variety`: title of the product\n",
    "- `str: Style`: categorical styles of the products, cup, pack or tray\n",
    "- `str: Country`: country of origin\n",
    "- `float: stars`: star rating of each product\n",
    "\n",
    "And here is the corresponding column specs<br>\n",
    "`i:reviewID s:brand s:variety s:style s:country f:stars`\n",
    "\n",
    "**Note**<br>\n",
    "When reading in the files with `aq-pp`, we'll be using bash's [variable substitution](http://www.compciv.org/topics/bash/variables-and-substitution/).\n",
    "\n",
    "#### Todo\n",
    "\n",
    "Operations that can be performed on data by leveraging `-eval` option can be broken down and simplied into 4 categories below.\n",
    "Things to cover in this section, are\n",
    "- ONIT: numerical evaluation\n",
    "    - constant and colname, on new column\n",
    "    - constant and colName, on existing column\n",
    "    - colName and ColName, on new column\n",
    "    - \n",
    "- string manipulation\n",
    "- data type conversion operation\n",
    "    - data type\n",
    "- any operation possible by builtin functions (aq-emod)\n",
    "\n",
    "\n",
    "Let's start with Numerical operations.\n",
    "\n",
    "**Numerical Operation**\n",
    "\n",
    "Operators supported for numerical operation are<br>\n",
    "\n",
    "_Arithmetic_\n",
    "- `*`: multiplication\n",
    "- `/`: division\n",
    "- `%`: modulus\n",
    "- `+`: addition\n",
    "- `-`: subtraction\n",
    "\n",
    "_Bitwise_\n",
    "- `&`: AND\n",
    "- `|`: OR\n",
    "- `^`: XOR\n",
    "\n",
    "First, we will double the value of star rating column, and assign it to a new column named `double_rating`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"double_rating\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,7.5\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,2\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,4.5\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,5.5\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,7.5\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,9.5\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,8\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,7.5\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,0.5\n"
     ]
    }
   ],
   "source": [
    "# First store filename and column spec in variable to simplify commands\n",
    "file=\"data/aq_pp/ramen-ratings-part.csv\"\n",
    "cols=\"i:reviewID s:brand s:variety s:style s:country f:stars\"\n",
    "# now create a column called double_rating, and assign the value of 2 * stars\n",
    "aq_pp -f,+1 $file -d $cols -eval f:double_rating '2*stars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the new column `double_rating` contains the value twice as large as the `stars` value.\n",
    "\n",
    "**Couple things to note**<br>\n",
    "- **Column Datatype:** the destination column's datatype has to be same as the datatype of result of the `Expr`. In the example above, the result is float datatype, therefore we've declared `double_rating` as float.\n",
    "- **Quotations:** you cannot quote `colName|colSpec`, while `Expr` to be evaluated needs to be quoted. Single quotation is recommended, because string value in the expression needs to be quoted as well.\n",
    "\n",
    "Now we will perform the same operation, but store the result on existing column, `stars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",7.5\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",2\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",4.5\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",5.5\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",7.5\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",9.5\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",8\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",7.5\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.5\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval stars '2*stars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply any of the other arithmetic operators just like above example. \n",
    "\n",
    "In the above example, `Expr` only contained existing column and a constant. We can also provide multiple columns as `Expr` and perform calculation.\n",
    "\n",
    "We'll divide the `reviewID` (int) by `stars`(float), and store the result in new column `div`(float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"div\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,688\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,2579\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,1145.7777777777778\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,937.09090909090912\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,686.93333333333328\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,542.10526315789468\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,643.5\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,686.13333333333333\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,10288\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval f:div 'reviewID/stars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**+ operator with string**<br>\n",
    "`+` operator can also be used to concatinate string values, besides numeric operation. As a example, we'll create a string column `s:info`, and store combined strings of `brand` and `country`, separated by ` - `. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"info\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,\"New Touch - Japan\"\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,\"Just Way - Taiwan\"\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,\"Nissin - USA\"\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,\"Wei Lih - Taiwan\"\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,\"Ching's Secret - India\"\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,\"Samyang Foods - South Korea\"\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,\"Acecook - Japan\"\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,\"Ikeda Shoku - Japan\"\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,\"Ripe'n'Dry - Japan\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval s:info 'brand+\" - \"+country'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `brand` and `country` are column names while ` - ` is a string constant, which is why it is double quoted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Builtin Variables](http://auriq.com/documentation/source/reference/manpages/aq_pp.html#eval)**\n",
    "You can also use builtin variables. There are couple of them, and here we'll take a look at `$RowNum` and `$Random`.\n",
    "\n",
    "Using `$RowNum`, we'll create a new integer column `row` and store the row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"row\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,1\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,2\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,3\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,4\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,5\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,6\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,7\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,8\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,9\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:row '$RowNum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are skipping the header row with `-f,+1` option, we'll correct the row numbers by addding 1 to each row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"row\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,2\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,3\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,4\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,5\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,6\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,7\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,8\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,9\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,10\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:row '$RowNum +1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"row\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,476707713\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,1186278907\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,505671508\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,2137716191\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,936145377\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,1215825599\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,589265238\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,924859463\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,1182112391\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:row '$random'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs very large positive integer. Sometimes we need random numbers within a certain range. Let's say between 0 and 10. Using modulus operator, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"row\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,3\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,7\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,8\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,1\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,7\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,9\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,8\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,3\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,1\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:row '$random%10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at bitwise operator, which performs bitwise logical operation on decimal numbers.\n",
    "\n",
    "For this, we'll use different file containing binary numbers, which looks like this\n",
    "\n",
    "number|mask\n",
    "---|---\n",
    "1|981\n",
    "290|90\n",
    "31|12\n",
    "79|56\n",
    "10|874\n",
    "\n",
    "Let's perform `|`(bitwise OR) operator on `numbers` column, with a constant 32. The result will be stored in the new column `i:result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"number\",\"mask\",\"result\"\n",
      "1,981,33\n",
      "290,90,290\n",
      "31,12,63\n",
      "79,56,111\n",
      "10,874,42\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 data/aq_pp/bitwise.csv -d i:number i:mask -eval i:result 'number | 32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `aq-pp` interpret numbers as decimal by default, therefore the bitwise operators will be calculated, and result will be shown as decimal number as well. \n",
    "\n",
    "**Data Conversion Operation**<br>\n",
    "\n",
    "Aq tools comes with various [builtin functions / aq-emod](http://auriq.com/documentation/source/reference/manpages/aq-emod.html) to manipulate, clean, convert different data types. \n",
    "We'll go over couple [data conversion functions](http://auriq.com/documentation/source/reference/manpages/aq-emod.html#general-data-conversion-functions) on this notebook.\n",
    "\n",
    "For the purpose of this sample, we will modify the column spec for ramen dataset, in order to input all the columns as string. \n",
    "\n",
    "After that, we'll create a new columns for `i:int_reviewID` to store converted integer value of `reviewID`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\"\n",
      "\"2580\",\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",\"3.75\"\n",
      "\"2579\",\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",\"1\"\n",
      "\"2578\",\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",\"2.25\"\n",
      "\"2577\",\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",\"2.75\"\n",
      "\"2576\",\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",\"3.75\"\n",
      "\"2575\",\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",\"4.75\"\n",
      "\"2574\",\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",\"4\"\n",
      "\"2573\",\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",\"3.75\"\n",
      "\"2572\",\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",\"0.25\"\n"
     ]
    }
   ],
   "source": [
    "cols=\"s:reviewID s:brand s:variety s:style s:country s:stars\"\n",
    "# input every columns as string\n",
    "aq_pp -f,+1 $file -d $cols "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `reviewID` and `stars` columns are quoted, showing that `aq_pp` is interpretting them as string at this point. Let's convert them into appropriate data types with builtin functions, \n",
    "- `ToF(Val)`: convert `Val` to float\n",
    "- `ToI(Val)`: convert `Val` to integer\n",
    "\n",
    "`Val` can be constant value or column names of string / numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"int_reviewID\"\n",
      "\"2580\",\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",\"3.75\",2580\n",
      "\"2579\",\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",\"1\",2579\n",
      "\"2578\",\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",\"2.25\",2578\n",
      "\"2577\",\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",\"2.75\",2577\n",
      "\"2576\",\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",\"3.75\",2576\n",
      "\"2575\",\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",\"4.75\",2575\n",
      "\"2574\",\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",\"4\",2574\n",
      "\"2573\",\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",\"3.75\",2573\n",
      "\"2572\",\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",\"0.25\",2572\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:int_reviewID 'ToI(reviewID)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided column name as `Val` in the example above, but can also provide a string constant. Note that you should always quote the string values in `-eval` options' `Expr`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"int_reviewID\"\n",
      "\"2580\",\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",\"3.75\",13\n",
      "\"2579\",\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",\"1\",13\n",
      "\"2578\",\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",\"2.25\",13\n",
      "\"2577\",\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",\"2.75\",13\n",
      "\"2576\",\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",\"3.75\",13\n",
      "\"2575\",\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",\"4.75\",13\n",
      "\"2574\",\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",\"4\",13\n",
      "\"2573\",\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",\"3.75\",13\n",
      "\"2572\",\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",\"0.25\",13\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:int_reviewID 'ToI(\"13\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builtin function can also be combined with arithmetic expression. Let's convert+ `\"13\"`(str constant) and `reviewID` into int, then add them together, then store the result on `i:result` column this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"result\"\n",
      "\"2580\",\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",\"3.75\",2593\n",
      "\"2579\",\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",\"1\",2592\n",
      "\"2578\",\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",\"2.25\",2591\n",
      "\"2577\",\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",\"2.75\",2590\n",
      "\"2576\",\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",\"3.75\",2589\n",
      "\"2575\",\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",\"4.75\",2588\n",
      "\"2574\",\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",\"4\",2587\n",
      "\"2573\",\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",\"3.75\",2586\n",
      "\"2572\",\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",\"0.25\",2585\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:result 'ToI(reviewID) + ToI(\"13\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 is added to the original `reviewID` value, on `result` column. \n",
    "\n",
    "We can also combine numeric strings by using `+`, convert the result to numeric data type, then store in a numeric column. Let's take a look.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"result\"\n",
      "\"2580\",\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",\"3.75\",258013\n",
      "\"2579\",\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",\"1\",257913\n",
      "\"2578\",\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",\"2.25\",257813\n",
      "\"2577\",\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",\"2.75\",257713\n",
      "\"2576\",\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",\"3.75\",257613\n",
      "\"2575\",\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",\"4.75\",257513\n",
      "\"2574\",\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",\"4\",257413\n",
      "\"2573\",\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",\"3.75\",257313\n",
      "\"2572\",\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",\"0.25\",257213\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval i:result 'ToI(reviewID + \"13\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**String Manipulation**<br>\n",
    "\n",
    "`-map` options will be covered under different notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
