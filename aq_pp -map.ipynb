{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aq_pp -map, -mapf, -mapc\n",
    "\n",
    "In this notebook, we'll go over `aq_pp`'s string extraction and mapping option `-map(f/c)`. \n",
    "\n",
    "\n",
    "## Pre-requsites\n",
    "Readers are assumed to be equipped with decent amount of knowledge of the followings.\n",
    "- `aq_pp`\n",
    "- `aq_input`\n",
    "- `aq_output`\n",
    "- Regex\n",
    "\n",
    "Also have [aq_pp official documentation](http://auriq.com/documentation/source/reference/manpages/aq_pp.html#map) open on your side for referece.\n",
    "**If you're already familiar with the syntax of the command, feel free to skip to [data](#data) section.**\n",
    "\n",
    "## Overview\n",
    "\n",
    "There are 3 types of map options, namely\n",
    "- `-map`: extract desired pattern(s) from given column, and map it back to the same column based on MapTo string.\n",
    "- `-mapf` & `-mapc`: these are used in pairs. `-mapf` specifies the source column to extract patterns from, and `-mapc` is used to specify destination column and mapping pattern.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "**Map**<br>\n",
    "```aq_pp ... -map[,AtrLst] colName \"MapFrom\" \"MapTo\"```\n",
    "\n",
    "**Mapf/Mapc**<br>\n",
    "```aq_pp ... -mapf,[AtrLst] ColName MapFrom -mapc ColSpec|ColName MapTo```\n",
    "\n",
    "Where\n",
    "- `[,AtrLst]`: list of attributes to provide. \n",
    "    * `ncas` for case insensitive match (Default is case sensitive)\n",
    "    * [regular expression attributes](http://auriq.com/documentation/source/reference/manpages/aq-emod.html#regex-attributes) to specify the type of regex being used.\n",
    "- `colName`: column name\n",
    "- `ColSpec`: column spec, in case of storing the result in a new column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## MapFrom\n",
    "This rule dictates the pattern to match with given string for extraction. Some of the major components of the MapFrom syntax are followings.\n",
    "- A literal: Matches literal characters / strings\n",
    "- wildcard: `%*` matches any numbers of bytes, and `%?` matches any 1 byte.\n",
    "- Variable: `%%varName%%` variable name surrounded by double `%` characters. The name can be referred later in `-mapc`'s MapTo string.\n",
    "> Variable can have some additional attributes, and the syntax for variables looks like below.<br>\n",
    "```%%VarName[:@class][:[chars]][:min[-max]][,brks]%%``` <a id='var_attr'></a>\n",
    "    * `:@class`: specifies the types of characters to match, such as `n` for 0~9, or `a` for a-z, and `b` for A-Z. \n",
    "    * `[chars]`: specifies which characters to be included in the variable. \n",
    "    * `min-max`: integers to restrict min and max numbers of characters \n",
    "    * `,brks`: specifies the list of characters at which the extraction should stop. \n",
    "    \n",
    "    E.g. `%%CAPITAL:@b:3-5%%`: should match a substring of capital alphabetical letter, length between 3 ~ 5.<br>\n",
    "    More attributes for MapFrom are available at [RT MapFrom Syntax](http://auriq.com/documentation/source/reference/manpages/aq_pp.html#rt-mapfrom-syntax)<br>\n",
    "    **Note:** Each attributes are separated by `;`\n",
    "    \n",
    "    \n",
    "## MapTo\n",
    "\n",
    "This string specifies the format to map the extracted value into destination column. It has somewhat similar rule to MapFrom syntax, such as\n",
    "- Literal: map constant characters / string\n",
    "- Variable: place the value stored in named variable. This variable can also take some attributes, looks like following.\n",
    "> ```%%VarName[:cnv][[:start]:length][,brks]%%```<br>\n",
    "    * `:cnv`: either `b64` or `url[Num]` convert the variable string to base 64 or url accordingly.\n",
    "    * `:start:length`: starting bytes position and subsequent length of the extracted variable. without the starting position, numbers of bytes from the beginning of the extracted variable.\n",
    "    * `,brks`: list of characters to stop substitution of variable.\n",
    "    \n",
    "    **Note:** each attributes are separated by `;`<br>\n",
    "    Details of MapTo is also available at [MapTo Syntax](http://auriq.com/documentation/source/reference/manpages/aq_pp.html#mapto-syntax)\n",
    "    \n",
    "## -Map(c/f)\n",
    "\n",
    "### MapFrom\n",
    "\n",
    "Let's start with simple string extraction using the options and variables.\n",
    "\n",
    "**Extracting Origin of Flight**<br>\n",
    "\n",
    "Using `-mapf` to extract the origin, and `-mapf` to map it to newly created column, here are the arguments to think about.\n",
    "\n",
    "- `-mapf`\n",
    "    - `ColName`: column to extract data from. This should be `search` column.\n",
    "    - `MapFrom`: pattern to match the 3 capital letter airport code following \"From=\" string, followed by \"To=...\". We'll be using a variable named `ORG` to extract and store the match.\n",
    "- `-mapc`\n",
    "    - `ColSpec`: column spec for new string column. We'll name it as Origin\n",
    "    - `MapTo`: We can place variable name `ORG` to the destination column, since we're not formatting the result in any way.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "<a id='data'></a>\n",
    "## Data\n",
    "\n",
    "We'll be using airline flight search history data (modified from the original for privacy purpose.) This dataset contains long string columns that are perfect for this tutorial.\n",
    "Below is what the data looks like.\n",
    "\n",
    "search|\n",
    "-----|\n",
    "From=HNDTo=NGODate=20150506Class=Y|\n",
    "From=NGik0To=OKADate=20150425Class=1|\n",
    "From=OKATo=NGODate=20l5o4A5Class=Y|\n",
    "From=OKATo=NGODate=20150425Class=S|\n",
    "From=OKATo=nG0ODate=20150425Class=3\n",
    "From=3GOTo=OKADate=S0150F25Class=Y|\n",
    "From=NGOTo=OKADate=20150419Class=Y|\n",
    "From=OKaTo=NGODate=20150517Class=Y|\n",
    "\n",
    "\n",
    "Each rows are record for a one search query, and from left to right, composted of\n",
    "- `From=*`: 3 capital letter alphabetical airport code\n",
    "- `To=*`: 3 capital letter alphabetical airport code\n",
    "- `Date=*`: Date of the flight\n",
    "- `Class=*`: class of flight, categorical value\n",
    "\n",
    "Some records in the data has invalid values intentionally for practice.\n",
    "\n",
    "## Sample\n",
    "\n",
    "### Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\"\n"
     ]
    }
   ],
   "source": [
    "# set up the column spec and file name\n",
    "file=\"data/aq_pp/airline_sample.csv\"\n",
    "col=\"S:search\"\n",
    "aq_pp -f,+1 $file -d $col "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Sample\n",
    "\n",
    "- [MapFrom](#mapfrom)\n",
    "\t- [Variable Attribute - String](#var_attr)\n",
    "\t- [Variable Attribute - Number](#var_num)\n",
    "- [MapTo](#mapto)\n",
    "\t- [Attributes](#attr)\n",
    "\t- [Map One Variable across Columns](#map_one_few)\n",
    "- [Multiple Variables](#mul_var)\n",
    "\t- [Mapping to Multiple Columns](#to_mul_col)\n",
    "\t- [Mapping from Multiple Columns](#from_mul_col)\n",
    "\t- [Advanced Examples](#adv_ex)\n",
    "- [Multiple Columns](#from_to_mul)\n",
    "- [Map](#map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mapfrom'></a>\n",
    "### MapFrom\n",
    "\n",
    "Using `-mapf` for extraction and `-mapto` for mapping the string with one variable named `ORG`. <br>\n",
    "Takig a closer look at MapFrom string, we have \n",
    "```From=%%ORG%%To=%*```<br>\n",
    "- `From=`: literal to match the substring before the origin airport code\n",
    "- `%%ORG%%`: variable named ORG\n",
    "- `To=`: String literal\n",
    "- `%*`: wildcard to match everything after \"To=\" in the column\n",
    "\n",
    "Precisely speaking, this expression. matches **ANY** substring between `From=` and `To=` which is followed by any numbers of bytes, and stores it in variable named `ORG`. Therefore you'll notice that invalid airport code are also extracted as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"Origin\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"ISG\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"OKA\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"ISG\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"ITM\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"HND\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"NGik0\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"HND\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"NGO\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"SPK\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"OKA\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search 'From=%%ORG%%To=%*' -mapc S:Origin '%%ORG%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='var_attr'></a>\n",
    "**Variable Attributes - string**<br>\n",
    "\n",
    "What if there are anomalies in the dataset, which include invalid airport code in the position between `From=` and `To=`? \n",
    "With the MapFrom expression above, it'll still pick up the invalid origin code and map it to the new column. In fact, take a look at the result above. You can see that some invalid airport codes are extracted as well, such as `NGik0`.\n",
    "\n",
    "How can we make sure that we're only extracting valid airport code? \n",
    "We can do it by specifying format of variable with attributes.\n",
    "\n",
    "In this case, we want to make sure that the extracted airport code look like...\n",
    "- capital alphabetical characters\n",
    "- exactly 3 letters long\n",
    "\n",
    "This can be achieved by providing [some attributes after the variable name](#var_attr) like below.<br>\n",
    "```%%ORG:@b:3-3%%```<br>\n",
    "where\n",
    "- `@b`: class to specify the characters are in range of A~Z\n",
    "- `3-3`: min and max numbers of characters in variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"Origin\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"ISG\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"OKA\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"ISG\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"ITM\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"HND\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"HND\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"NGO\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"SPK\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"OKA\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search 'From=%%ORG:@b:3-3%%To=%*' -mapc S:Origin '%%ORG%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, only valid airport codes are extracted and mapped to Origin column while invalid ones are left blank (meaning no match was found).\n",
    "This can be used as data validation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='var_attr_num'></a>\n",
    "**Variable Attribute - number**<br>\n",
    "\n",
    "Let us try to extract numeric values, namely year, month and date data. We will be using similar tactics used above to filter out the invalid numeric record as well. Here are example of valid and invalid numeric record.\n",
    "\n",
    "* Valid: `...Date=20150425Class...`\n",
    "* Invalid: `...Date=S0150F25Class...`\n",
    "\n",
    "Valid date data is followed by `..Date=` substring, and have a format of 8 digits nubmers, 4 digit for year, 2 for month and date.\n",
    "Let's extract all 8 digits, store it in `TIME` variable, and map it in `time` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"time\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"20150904\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"20150426\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"20151016\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"20171112\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"20150425\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"20160528\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"20160207\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"20150425\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search '%*Date=%%TIME:@n:8-8%%Class%*' -mapc S:time '%%TIME%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little about MapFrom string, ```%*Date=%%TIME:@n:8-8%%Class%*```<br>\n",
    "- `%*`: 2 of them are used in the beginning and at the end to skip the unneccesary string.\n",
    "- `Date=`, `Class`: literals that preceed and follows the variable\n",
    "- `%%TIME:@n:8-8%%`:variable, with attributes of ...\n",
    "    - `@n`: numbers of 0~9\n",
    "    - `8-8`: min 8 and max 8 length\n",
    "    \n",
    "You can see that only valid date data are extracted, and rest are left blank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mapto'></a>\n",
    "### MapTo\n",
    "\n",
    "We've focused on usage of MapFrom with `-mapf/c` to extract patterns, and kept use of MapTo simple in previous sections.<br>\n",
    "In this part of the notebook, we'll take a look at how to use MapTo string to specify formatting of destination column.\n",
    "\n",
    "In this example, we'll keep using same `-mapf` string that we've used to extract 8 digit datetime value. <br>\n",
    "\n",
    "**Literal and Variable**<br>\n",
    "To make the content of the column clear, we'd like to map the date digits in format of <br>\n",
    "```date=20180904```.\n",
    "\n",
    "How can we map this using MapTo? We knows that `%%varName%%` will substitute the extracted value. All we need is the literal string of `date=` before that. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"time\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"date=20150904\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"date=20150426\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"date=\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"date=20151016\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"date=20171112\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"date=20150425\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"date=\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"date=20160528\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"date=20160207\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"date=20150425\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search '%*Date=%%TIME:@n:8-8%%Class%*' \\\n",
    "-mapc S:time 'date=%%TIME%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attr'></a>\n",
    "**Attributes**<br>\n",
    "\n",
    "There are 3 attributes available and we'll cover 2 of them, \n",
    "- `:length`: numbers of bytes from the beginning of the value stored in the variable\n",
    "- `:start:length`: starting byte position and **subsequent** length of the extracted value. Starting at 0.\n",
    "\n",
    "We've extracted 8 digits, but would only like to use year portion (first 4 digits) of the data. We can accomplish this using `:length` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"time\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"Year=2015\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"Year=2015\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"Year=\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"Year=2015\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"Year=2017\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"Year=2015\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"Year=\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"Year=2016\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"Year=2016\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"Year=2015\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search '%*Date=%%TIME:@n:8-8%%Class%*' \\\n",
    "-mapc S:time 'Year=%%TIME:4%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we'd like to map only month (2 digits in the middle)? We can use `:start:length` attributes. Note that `start` is starting byte to substitute, an index starting from zero, and `length` is subsequent length.<br>\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"time\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"Month=09\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"Month=04\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"Month=\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"Month=10\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"Month=11\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"Month=04\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"Month=\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"Month=05\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"Month=02\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"Month=04\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search '%*Date=%%TIME:@n:8-8%%Class%*' \\\n",
    "-mapc S:time 'Month=%%TIME:4:2%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks correct!\n",
    "\n",
    "<a id='map_one_few'></a>\n",
    "**Mapping one variable across columns**<br>\n",
    "\n",
    "In the 2 examples above, we have mapped part of `TIME` variable only onece.\n",
    "However, in case if you'd like to map different part of one variable, for instance mapping year and month separately into individual columns it is possible.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"time\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"Year=2015, Month=09\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"Year=2015, Month=04\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"Year=, Month=\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"Year=2015, Month=10\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"Year=2017, Month=11\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"Year=2015, Month=04\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"Year=, Month=\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"Year=2016, Month=05\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"Year=2016, Month=02\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"Year=2015, Month=04\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search '%*Date=%%TIME:@n:8-8%%Class%*' \\\n",
    "-mapc S:time 'Year=%%TIME:4%%, Month=%%TIME:4:2%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mul_var'></a>\n",
    "### Multiple Variables\n",
    "\n",
    "Let's say we'd like to extract multiple substrings from one columns, such as \n",
    "- origin\n",
    "- destination\n",
    "- year\n",
    "- month\n",
    "- date\n",
    "\n",
    "\n",
    "We can do this by using multiple variables, and assigning each string patterns to them. For simplicity, we'll start with 2 variables, in order to extract origin and destination.<br>\n",
    "Basic rule does not change when using multiple variables. You can fit them into one MapFrom and MapTo string. For example, to extract origin and destination, \n",
    "\n",
    "```From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%%*```\n",
    "\n",
    "And we'll be mapping both values in a single column for now in a format of `Origin=airport_code, Destination=airport_code`\n",
    "\n",
    "Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"airports\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"Origin=ISG, Destination=OKA\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"Origin=OKA, Destination=ITM\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"Origin=ISG, Destination=OKA\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"Origin=ITM, Destination=FUK\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"Origin=HND, Destination=KOJ\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"Origin=, Destination=\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"Origin=HND, Destination=ITM\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"Origin=NGO, Destination=SPK\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"Origin=SPK, Destination=NGO\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"Origin=, Destination=\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search 'From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%%*' \\\n",
    "-mapc S:airports 'Origin=%%ORG%%, Destination=%%DEST%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale up to extracting 3 substrings, origin, destination and date (year, month and date).\n",
    "\n",
    "For extraction, we can simply combine 3 variables together in MapFrom, like following.\n",
    "\n",
    "`From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%Date=%%TIME:@n:8-8%%%*`\n",
    "\n",
    "And Map it in format of \n",
    "\n",
    "`Origin=airport_code, Destination=airport_code, date=date_digits` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"airports\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"Origin=ISG, Destination=OKA, Date=20150904\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"Origin=OKA, Destination=ITM, Date=20150426\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",\"Origin=, Destination=, Date=\"\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"Origin=ITM, Destination=FUK, Date=20151016\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"Origin=HND, Destination=KOJ, Date=20171112\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",\"Origin=, Destination=, Date=\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",\"Origin=, Destination=, Date=\"\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"Origin=NGO, Destination=SPK, Date=20160528\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"Origin=SPK, Destination=NGO, Date=20160207\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",\"Origin=, Destination=, Date=\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search 'From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%Date=%%TIME:@n:8-8%%%*' \\\n",
    "-mapc S:airports 'Origin=%%ORG%%, Destination=%%DEST%%, Date=%%TIME%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='from_to_mul'></a>\n",
    "### Mapping Multiple Columns\n",
    "\n",
    "We've been extracting all the strings from one column, and mapping it onto another single column so far. But this is not sufficient for occasion such as when you'd like to extract multiple data, and map it across several columns, or combine data from multiple columns into one column.\n",
    "\n",
    "`-mapf` and `-mapc` supports such operation. Users can use these options multiple times to map to and from multiple columns. Each `-mapf` option and `-mapc` option is capable of extracting and mapping into single column, so you'd need to use these optiolns as many times as the numbers of columns you're dealing with. \n",
    "\n",
    "For example, if you'd like to extract data from 2 columns, and map them into 3 columns, then you'd need to use 2 `-mapf` options and 3 `-mapc` options. We'll take a look at them individually.\n",
    "\n",
    "<a id='to_mul_col'></a>\n",
    "**Mapping To Multiple Columns**<br>\n",
    "\n",
    "In this first example, we'll take 3 extracted strings (origin, destination and date) and put them into 3 different columns accordingly. This does not change `-mapf` option, so pay attention to the 3 `-mapc` options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"Origin\",\"Destination\",\"Date\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"ISG\",\"OKA,\",\"20150904\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"OKA\",\"ITM,\",\"20150426\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",,\",\",\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"ITM\",\"FUK,\",\"20151016\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"HND\",\"KOJ,\",\"20171112\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",,\",\",\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",,\",\",\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"NGO\",\"SPK,\",\"20160528\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"SPK\",\"NGO,\",\"20160207\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",,\",\",\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search 'From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%Date=%%TIME:@n:8-8%%%*' \\\n",
    "-mapc S:Origin '%%ORG%%' -mapc S:Destination '%%DEST%%', -mapc S:Date '%%TIME%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next example, we'll further split `TIME` data into three columns, namely Year, Month and Date. \n",
    "In order to split the `TIME` variable into 3 columns, we can again use `:start:length` attribute for MapTo string.<br>\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\",\"Origin\",\"Destination\",\"Year\",\"Month\",\"Date\"\n",
      "\"From=ISGTo=OKADate=20150904Class=Y\",\"ISG\",\"OKA\",\"2015\",\"09\",\"04\"\n",
      "\"From=OKATo=ITMDate=20150426Class=Y\",\"OKA\",\"ITM\",\"2015\",\"04\",\"26\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\",,,,,\n",
      "\"From=ITMTo=FUKDate=20151016Class=Y\",\"ITM\",\"FUK\",\"2015\",\"10\",\"16\"\n",
      "\"From=HNDTo=KOJDate=20171112Class=Y\",\"HND\",\"KOJ\",\"2017\",\"11\",\"12\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\",,,,,\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\",,,,,\n",
      "\"From=NGOTo=SPKDate=20160528Class=S\",\"NGO\",\"SPK\",\"2016\",\"05\",\"28\"\n",
      "\"From=SPKTo=NGODate=20160207Class=S\",\"SPK\",\"NGO\",\"2016\",\"02\",\"07\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\",,,,,\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -mapf search 'From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%Date=%%TIME:@n:8-8%%%*' \\\n",
    "-mapc S:Origin '%%ORG%%' -mapc S:Destination '%%DEST%%' \\\n",
    "-mapc S:Year '%%TIME:4%%' -mapc S:Month '%%TIME:4:2%%' -mapc S:Date '%%TIME:6:8%%' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='from_mul_col'></a>\n",
    "**Mapping From Multiple Columns**<br>\n",
    "\n",
    "Because the flight search data we've been using only have one source column, we'll use differnt dataset for this one particular example. \n",
    "[Titanic survivor dataset](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html) is a dataset of passengers of titanic and whether they made it out alive or not.\n",
    "The actual data look like below.\n",
    "\n",
    "Survived|Pclass|Name|Sex|Age|Siblings_Spouses_Aboard|Parents_Children_Aboard|Fare\n",
    "-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "1|2|Mrs. Amin S (Marie Marthe Thuillard) Jerwan|female|23|0|0|13.791700000000001\n",
    "0|3|Mr. William Thomas Beavan|male|19|0|0|8.0500000000000007\n",
    "1|1|Miss. Kornelia Theodosia Andrews|female|63|1|0|77.958299999999994\n",
    "0|3|Master. Eino Viljami Panula|male|1|4|1|39.6875\n",
    "1|1|Mr. Algernon Henry Wilson Barkworth|male|80|0|0|30\n",
    "0|3|Mr. Farred Chehab Emir|male|26|0|0|7.2249999999999996\n",
    "\n",
    "\n",
    "\n",
    "Let's say we'd like to create a summary column of information composed of\n",
    "- Survived or not\n",
    "- Age\n",
    "\n",
    "Note that we'll be interpreting all of the columns as string, so that we can apply the options, and will keep it to 2 columns for now. We can do this by using 2 `-mapf` and a single `-mapc` option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Survived\",\"Age\",\"Summary\"\n",
      "\"1\",\"23.0\",\"Age: 23.0 Alive: 1\"\n",
      "\"0\",\"19.0\",\"Age: 19.0 Alive: 0\"\n",
      "\"1\",\"63.0\",\"Age: 63.0 Alive: 1\"\n",
      "\"0\",\"1.0\",\"Age: 1.0 Alive: 0\"\n",
      "\"1\",\"80.0\",\"Age: 80.0 Alive: 1\"\n",
      "\"0\",\"26.0\",\"Age: 26.0 Alive: 0\"\n",
      "\"0\",\"22.0\",\"Age: 22.0 Alive: 0\"\n",
      "\"1\",\"42.0\",\"Age: 42.0 Alive: 1\"\n",
      "\"1\",\"33.0\",\"Age: 33.0 Alive: 1\"\n",
      "\"1\",\"35.0\",\"Age: 35.0 Alive: 1\"\n",
      "\"1\",\"4.0\",\"Age: 4.0 Alive: 1\"\n",
      "\"0\",\"26.0\",\"Age: 26.0 Alive: 0\"\n",
      "\"1\",\"48.0\",\"Age: 48.0 Alive: 1\"\n",
      "\"1\",\"38.0\",\"Age: 38.0 Alive: 1\"\n",
      "\"0\",\"24.0\",\"Age: 24.0 Alive: 0\"\n",
      "\"1\",\"34.0\",\"Age: 34.0 Alive: 1\"\n",
      "\"1\",\"48.0\",\"Age: 48.0 Alive: 1\"\n",
      "\"1\",\"19.0\",\"Age: 19.0 Alive: 1\"\n",
      "\"0\",\"45.0\",\"Age: 45.0 Alive: 0\"\n",
      "\"0\",\"55.0\",\"Age: 55.0 Alive: 0\"\n"
     ]
    }
   ],
   "source": [
    "# set up the params\n",
    "sunken_ship=\"data/aq_pp/titanic.csv\"\n",
    "ship_col=\"S:Survived S:Pclass S:Name S:Sex S:Age S:Siblings_Spouses_Aboard S:Parents_Children_Aboard S:Fare\"\n",
    "\n",
    "aq_pp -f,+1 $sunken_ship -d $ship_col -mapf Survived '%%STATE%%' -mapf Age '%%AGE%%' \\\n",
    "-mapc S:Summary 'Age: %%AGE%% Alive: %%STATE%%' -c Survived Age Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adv_ex'></a>\n",
    "**Advanced Example**<br>\n",
    "Let's try something little more complicated. \n",
    "We'd like to combine following information\n",
    "- Sex\n",
    "- Age\n",
    "- Passenger Class\n",
    "- A person's title (included in the Name column, \"Mr\", \"Mrs\", etc)\n",
    "\n",
    "into a summary column. Also we'd like to extract a person's name only (without the title) and map it into name column.\n",
    "So we're extracting from 4 columns (`Sex`, `Age`, `PClass`, and `Name`) and mapping into 2 columns (`Summary` and `Brith Name`).\n",
    "\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Summary\",\"Birth_name\"\n",
      "\"Title: Mrs, Sex: female, Age: 23.0, Class: 2\",\" Amin S (Marie Marthe Thuillard) Jerwan\"\n",
      "\"Title: Mr, Sex: male, Age: 19.0, Class: 3\",\" William Thomas Beavan\"\n",
      "\"Title: Miss, Sex: female, Age: 63.0, Class: 1\",\" Kornelia Theodosia Andrews\"\n",
      "\"Title: Master, Sex: male, Age: 1.0, Class: 3\",\" Eino Viljami Panula\"\n",
      "\"Title: Mr, Sex: male, Age: 80.0, Class: 1\",\" Algernon Henry Wilson Barkworth\"\n",
      "\"Title: Mr, Sex: male, Age: 26.0, Class: 3\",\" Farred Chehab Emir\"\n",
      "\"Title: Mr, Sex: male, Age: 22.0, Class: 1\",\" Sante Ringhini\"\n",
      "\"Title: Mrs, Sex: female, Age: 42.0, Class: 2\",\" Charles Alexander (Alice Adelaide Slow) Louch\"\n",
      "\"Title: Mrs, Sex: female, Age: 33.0, Class: 3\",\" Karl Alfred (Maria Mathilda Gustafsson) Backstrom\"\n",
      "\"Title: Mr, Sex: male, Age: 35.0, Class: 1\",\" Gustave J Lesurer\"\n",
      "\"Title: Master, Sex: male, Age: 4.0, Class: 3\",\" Harold Theodor Johnson\"\n",
      "\"Title: Mr, Sex: male, Age: 26.0, Class: 3\",\" Henrik Juul Hansen\"\n",
      "\"Title: Lady, Sex: female, Age: 48.0, Class: 1\",\" (Lucille Christiana Sutherland)Duff Gordon\"\n",
      "\"Title: Mr, Sex: male, Age: 38.0, Class: 1\",\" Frederick Maxfield Hoyt\"\n",
      "\"Title: Mr, Sex: male, Age: 24.0, Class: 3\",\" Francesco Celotti\"\n",
      "\"Title: Mr, Sex: male, Age: 34.0, Class: 1\",\" Frederic Kimber Seward\"\n",
      "\"Title: Mrs, Sex: female, Age: 48.0, Class: 2\",\" Samuel (Jane Laver) Herman\"\n",
      "\"Title: Miss, Sex: female, Age: 19.0, Class: 1\",\" Margaret Edith Graham\"\n",
      "\"Title: Mr, Sex: male, Age: 45.0, Class: 1\",\" Victor Robbins\"\n",
      "\"Title: Mr, Sex: male, Age: 55.0, Class: 3\",\" Frederick William Shellard\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $sunken_ship -d $ship_col \\\n",
    "-mapf Sex '%%SEX%%' -mapf Age '%%AGE%%' -mapf Pclass '%%CLASS%%' -mapf Name '%%TITLE:[ CDJLMRSadehijklmnoprstuvy]:2-12%%.%%NAME%%' \\\n",
    "-mapc S:Summary 'Title: %%TITLE%%, Sex: %%SEX%%, Age: %%AGE%%, Class: %%CLASS%%' -mapc S:Birth_name '%%Name%%' -c Summary Birth_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the \n",
    "* 1st line, we're setting up the input and column spec for the dataset\n",
    "* 2nd line, 4 `-mapf` was used to extract total of 5 variables\n",
    "    * On MapFrom string `%%TITLE:[ CDJLMRSadehijklmnoprstuvy]:2-12%%.%%NAME%%`, we're extracting 2 variables. \n",
    "        * `TITLE` variable by\n",
    "            * 2-12 character long: `2-12`\n",
    "            * It is composed of the following characters: `[ CDJLMRSadehijklmnoprstuvy]`, including the white space\n",
    "        * `NAME` variable\n",
    "        \n",
    "* 3rd line, with 2 `-mapc` we map the results on column Summary and Birth_name, then output only these two on stduot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='map'></a>\n",
    "## `-Map`\n",
    "\n",
    "`-map` option extract string from a column, and map it back to the source column.\n",
    "Quickly reviewing it's syntax, it looks like follwoing...<br>\n",
    "```aq_pp ... -map[,AtrLst] colName \"MapFrom\" \"MapTo\"```\n",
    "\n",
    "Note that both MapFrom and MapTo string are located right after the `colName`, which is the source and destination column in this case.\n",
    "\n",
    "Almost everything we've covered in `-mapf/c` section can be also done with `-map` option. Followings are some of the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with basic, let's extract origin airport code from the `search` column, and map it back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\"\n",
      "\"Origin=ISG\"\n",
      "\"Origin=OKA\"\n",
      "\"Origin=ISG\"\n",
      "\"Origin=ITM\"\n",
      "\"Origin=HND\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\"\n",
      "\"Origin=HND\"\n",
      "\"Origin=NGO\"\n",
      "\"Origin=SPK\"\n",
      "\"Origin=OKA\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -map search 'From=%%ORG:@b:3-3%%To=%*' 'Origin=%%ORG%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** When there are no match in the string, it will simply display the original content of the column. Therefore in practice it's good to filter out unmatched record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try extracting origin, destination and date, and mapping the three values back to search column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"search\"\n",
      "\"ORN=ISG, DEST=OKA, Time=20150904\"\n",
      "\"ORN=OKA, DEST=ITM, Time=20150426\"\n",
      "\"From=ISGTo=OKADate=2015o406Class=Y\"\n",
      "\"ORN=ITM, DEST=FUK, Time=20151016\"\n",
      "\"ORN=HND, DEST=KOJ, Time=20171112\"\n",
      "\"From=NGik0To=OKADate=20150425Class=1\"\n",
      "\"From=HNDTo=ITMDate=20l518920113Class=S\"\n",
      "\"ORN=NGO, DEST=SPK, Time=20160528\"\n",
      "\"ORN=SPK, DEST=NGO, Time=20160207\"\n",
      "\"From=OKATo=nG0ODate=20150425Class=3\"\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $col -map search 'From=%%ORG:@b:3-3%%To=%%DEST:@b:3-3%%Date=%%TIME:@n:8-8%%%*' \\\n",
    "'ORN=%%ORG%%, DEST=%%DEST%%, Time=%%TIME%%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MapTo string include 3 variable name as well as literal strings to format them.\n",
    "**Split the time column into year, month and date with literal string mapping and Each Columns**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
