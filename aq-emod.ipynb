{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aq-emod\n",
    "\n",
    "`aq-emod` is a collection of builtin functions that can perform some complex data processing and manipulation, when used with other aq_tools.\n",
    "Functionality varies from simple mathematical function, URL encoding functions to complex string extraction functions.\n",
    "We will take a look at syntax of these functions, as well as very basic sample usage of each functions that were not covered in the documentation.\n",
    "\n",
    "## Prerequsites\n",
    "\n",
    "Readers of this notebook is expected to know\n",
    "\n",
    "* Bash commands\n",
    "* Regular Expressions\n",
    "* use of aq_input / input-spec and column spec with `aq_pp` command\n",
    "\n",
    "We won't go over input, column and output spec on this notebook. They can be found on \n",
    "- [aq-input](aq_input.ipynb).\n",
    "- [aq-output](aq_output.ipynb)\n",
    " \n",
    "\n",
    "Also have the [aq-emod documentation](http://auriq.com/documentation/source/reference/manpages/aq-emod.html) ready on your side, so you can refer to the details of each options as needed.\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "Roughly speaking, `aq-emod` functions / builtin functions can be categorized into the followings.\n",
    "\n",
    "- [String property functions](#string_property)\n",
    "- [Math functions](#math)\n",
    "- [Comparison functions](#comparison)\n",
    "- [Data extraction and encode/decode functions](#extract_code)\n",
    "- [General data conversion functions](#conversion)\n",
    "- [Date/Time conversion functions](#date_time)\n",
    "- [Character set encoding conversion functions](#character_encoding)\n",
    "- [Key hashing functions](#key_hashing)\n",
    "- [Speciality functions](#speciality)\n",
    "- [RTmetrics functions](#rtmetrics)\n",
    "- [Udb specific functions](#udb)\n",
    "\n",
    "Note that we'll be taking a look at each function using `aq_pp` command's `-eval` option. Below is the basic syntax of the command.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "\n",
    "```aq-pp ... -eval ColSpec|ColName Expr```\n",
    "\n",
    "where\n",
    "- `ColSpec`: new column's column spec to assign the result\n",
    "- `ColName`: existing column name to assign the result\n",
    "- `Expr`: expression to be evaluated. This is where `aq-emod` functions reside.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "[Ramen Ratings Dataset](https://www.kaggle.com/residentmario/ramen-ratings) from kaggle will be used in this sample, which contains ratings of 2500 ramen products. \n",
    "\n",
    "Review|Brand|Variety|Style|Country|Stars\n",
    "---|---|---|---|---|---|\n",
    "2580|New Touch|T's Restaurant Tantanmen|Cup|Japan|3.75\n",
    "2579|Just Way|Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles|Pack|Taiwan|1\n",
    "2578|Nissin|Cup Noodles Chicken Vegetable|Cup|USA|2.25\n",
    "2577|Wei Lih|GGE Ramen Snack Tomato Flavor|Pack|Taiwan|2.75\n",
    "2576|Ching's Secret|Singapore Curry|Pack|India|3.75\n",
    "2575|Samyang Foods|Kimchi song Song Ramen|Pack|South Korea|4.75\n",
    "2574|Acecook|Spice Deli Tantan Men With Cilantro|Cup|Japan|4\n",
    "2573|Ikeda Shoku|Nabeyaki Kitsune Udon|Tray|Japan|3.75\n",
    "2572|Ripe'n'Dry|Hokkaido Soy Sauce Ramen|Pack|Japan|0.25\n",
    "2571|KOKA|The Original Spicy Stir-Fried Noodles|Pack|Singapore|2.5\n",
    "\n",
    "Columns and corresponing data types for the dataset are follows.\n",
    "- `int: Review #`: review id number, the more recent the review is, the bigger the number is\n",
    "- `str: Brand`: brand / manufacture of the product\n",
    "- `str: Variety`: title of the product\n",
    "- `str: Style`: categorical styles of the products, cup, pack or tray\n",
    "- `str: Country`: country of origin\n",
    "- `float: stars`: star rating of each product\n",
    "\n",
    "Some smaller dataset will be used for some examples; they will be introduced along the way.<br>\n",
    "\n",
    "## Input and Column Specification\n",
    "\n",
    "Here is the corresponding column specs for the data<br>\n",
    "`i:reviewID s:brand s:variety s:style s:country f:stars`\n",
    "\n",
    "**Note**<br>\n",
    "When reading in the files with `aq-pp`, we'll be using bash's [variable substitution](http://www.compciv.org/topics/bash/variables-and-substitution/) to keep the command short and clean. For instance, \n",
    "```bash\n",
    "# assign file name & path to variable 'file'\n",
    "file='data/aq_pp/fileName.csv'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25\n"
     ]
    }
   ],
   "source": [
    "file=\"data/aq_pp/ramen-ratings-part.csv\"\n",
    "cols=\"i:reviewID s:brand s:variety s:style s:country f:stars\"\n",
    "aq_pp -f,+1 $file -d $cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='string_property'></a>\n",
    "### String Property Functions\n",
    "\n",
    "\n",
    "**`SHash(Val)`**:Returns the numeric hash value of a string.<br>\n",
    "Val can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "\n",
    "In this example, we'll hash `style` column, which value consists of Cup, Pack or Tray, and store the result in `style_hash` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"style\",\"style_hash\"\n",
      "\"Cup\",193488781\n",
      "\"Pack\",2090607556\n",
      "\"Cup\",193488781\n",
      "\"Pack\",2090607556\n",
      "\"Pack\",2090607556\n",
      "\"Pack\",2090607556\n",
      "\"Cup\",193488781\n",
      "\"Tray\",2090769765\n",
      "\"Pack\",2090607556\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:style_hash' 'SHash(style)' -c style style_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that same original string value results in equal hash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`SLeng(Val)`**:Returns the length of a string.<br>\n",
    "Val can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "    \n",
    "Again in this example, we'll provide `style` column, and result will be stored in `style_len` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"style\",\"style_len\"\n",
      "\"Cup\",3\n",
      "\"Pack\",4\n",
      "\"Cup\",3\n",
      "\"Pack\",4\n",
      "\"Pack\",4\n",
      "\"Pack\",4\n",
      "\"Cup\",3\n",
      "\"Tray\",4\n",
      "\"Pack\",4\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:style_len' 'SLeng(style)' -c style style_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='math'></a>\n",
    "### Math Functions\n",
    "<br>\n",
    "\n",
    "**Basics for math functions**\n",
    "\n",
    "Besides few exceptions, math function will take a single argument `Val` which can be numeric column, constant or expression that will result in numeric value. \n",
    "We will go over just a few of them here, plus functions with irregular syntax. For the list of all available math functions, refer to the [aq-emod documentation](http://auriq.com/documentation/source/reference/manpages/aq-emod.html#math-functions).\n",
    "\n",
    "**`Ceil(Val)`**: Rounds Val up to the nearest integral value and returns the result.\n",
    "\n",
    "Val can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "`stars` column that contains average star rating will be provided and result will be stored in `ceiling` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stars\",\"ceiling\"\n",
      "3.75,4\n",
      "1,1\n",
      "2.25,3\n",
      "2.75,3\n",
      "3.75,4\n",
      "4.75,5\n",
      "4,4\n",
      "3.75,4\n",
      "0.25,1\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:ceiling' 'Ceil(stars)' -c stars ceiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Floor(Val)`**: Rounds Val down to the nearest integral value and returns the result.\n",
    "\n",
    "Val can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "Similary to `Ceil()`, we'll use `stars` column again. Notice the difference in the result compare to `Ceil()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stars\",\"floor\"\n",
      "3.75,3\n",
      "1,1\n",
      "2.25,2\n",
      "2.75,2\n",
      "3.75,3\n",
      "4.75,4\n",
      "4,4\n",
      "3.75,3\n",
      "0.25,0\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:floor' 'Floor(stars)' -c stars floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**`Round(Val)`**: Rounds Val up/down to the nearest integral value and returns the result. Half way cases are rounded away from zero.\n",
    "Val can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "\n",
    "Given `star` column, the result will be rounded to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stars\",\"round\"\n",
      "3.75,4\n",
      "1,1\n",
      "2.25,2\n",
      "2.75,3\n",
      "3.75,4\n",
      "4.75,5\n",
      "4,4\n",
      "3.75,4\n",
      "0.25,0\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:round' 'round(stars)' -c stars round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Sqrt(Val)`**: Computes the square root of Val.\n",
    "\n",
    "Val can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "In this example, we will provide an constant `9` as an argument for clearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"squared\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,3\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,3\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,3\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,3\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,3\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,3\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,3\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,3\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,3\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:squared' 'Sqrt(9)' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math functions with irregular syntax**\n",
    "\n",
    "These functions require multiple values as their arguments to return the result.\n",
    "\n",
    "**`Min(Val1, Val2 [, Val3 ...])`**: Returns the smallest value among Val1, Val2 and so on.\n",
    "\n",
    "Each Val can be a numeric column’s name, a number, or an expression that evaluates to a number.\n",
    "    If all values are integers, the result will also be an integer.\n",
    "    If any value is a floating point number, the result will be a floating point number.\n",
    "We'll provide a constant, as well as `stars` column to be compared with, and store the result in a column called `smaller`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stars\",\"min\"\n",
      "3.75,3\n",
      "1,1\n",
      "2.25,2.25\n",
      "2.75,2.75\n",
      "3.75,3\n",
      "4.75,3\n",
      "4,3\n",
      "3.75,3\n",
      "0.25,0.25\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'f:min' 'Min(3, stars)'  -c stars min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Pow(Val, Power)`**: Computes Val raised to the power of Power.\n",
    "\n",
    "Val and Power can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "\n",
    "In this example, we'll calculate a 8th power of 2, meaning `Val = 2` and `Power = 8`, and result will be in a integer column called `byte`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reviewID\",\"brand\",\"variety\",\"style\",\"country\",\"stars\",\"byte\"\n",
      "2580,\"New Touch\",\"T's Restaurant Tantanmen \",\"Cup\",\"Japan\",3.75,256\n",
      "2579,\"Just Way\",\"Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles\",\"Pack\",\"Taiwan\",1,256\n",
      "2578,\"Nissin\",\"Cup Noodles Chicken Vegetable\",\"Cup\",\"USA\",2.25,256\n",
      "2577,\"Wei Lih\",\"GGE Ramen Snack Tomato Flavor\",\"Pack\",\"Taiwan\",2.75,256\n",
      "2576,\"Ching's Secret\",\"Singapore Curry\",\"Pack\",\"India\",3.75,256\n",
      "2575,\"Samyang Foods\",\"Kimchi song Song Ramen\",\"Pack\",\"South Korea\",4.75,256\n",
      "2574,\"Acecook\",\"Spice Deli Tantan Men With Cilantro\",\"Cup\",\"Japan\",4,256\n",
      "2573,\"Ikeda Shoku\",\"Nabeyaki Kitsune Udon\",\"Tray\",\"Japan\",3.75,256\n",
      "2572,\"Ripe'n'Dry\",\"Hokkaido Soy Sauce Ramen\",\"Pack\",\"Japan\",0.25,256\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'i:byte' 'Pow(2, 8)' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`IsInf(Val)`**: Tests if Val is infinite.\n",
    "\n",
    "Returns 1, -1 or 0 if the value is positive infinity, negative infinity or finite respectively.\n",
    "`Val` can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "\n",
    "In order to provide \"negative infinity\", we'll provide an expression `-1.0/0`, which will get evaluated to a negative infinity, and `IsInf()` should returns -1.\n",
    "\n",
    "**Note:** \n",
    "* In order to get positive / negative infinity, the expression needs to be evaluated as float(e.g. `1.0/0` instead of `1/0`).\n",
    "* The column to assign the result needs to be a **datatype of signed integer**, either `is` or `ls`, in order to be able to display negative values correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"IsInf\"\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:IsInf' 'IsInf(-1.0/0)' -c IsInf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='comparison'></a>\n",
    "### Comparison Functions\n",
    "\n",
    "Most of the comparision function compare 1 or more string constant, pattern or regex against whole / part of given string or string column. They return 1 if there are match, and 0 for no match. \n",
    "\n",
    "Let's start with function that compares beginning and end of the string with given pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`BegCmp(Val, BegStr [, BegStr ...])`**: examine if string `Val` start exactly with `BegStr`. \n",
    "\n",
    "* Returns 1 if there is a match, 0 otherwise.\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* Each `BegStr` is a string constant that specifies the starting string to match.\n",
    "\n",
    "Let's use `style` column again to demonstrate this function. I will give \"P\" as a pattern to match, and this should return 1 whenever `style` column's content start with \"P\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"style\",\"beginWith\"\n",
      "\"Cup\",0\n",
      "\"Pack\",1\n",
      "\"Cup\",0\n",
      "\"Pack\",1\n",
      "\"Pack\",1\n",
      "\"Pack\",1\n",
      "\"Cup\",0\n",
      "\"Tray\",0\n",
      "\"Pack\",1\n"
     ]
    }
   ],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'BegCmp(style, \"P\")' -c style beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide multiple `BegStr` to match with string that starts with any of the given `BegStr`. You can observe that this time it returns 1 for string that start with either \"P\" or \"Tr\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'BegCmp(style, \"P\", \"Tr\")' -c style beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`EndCmp(Val, EndStr [, EndStr ...])`**: Compares one or more ending string EndStr with the tail of Val. All the comparisons are case sensitive.\n",
    "\n",
    "* Returns 1 if there is a match, 0 otherwise.\n",
    "* Val can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* Each `EndStr` is a string constant that specifies the ending string to match.\n",
    "\n",
    "This compares the ending of `Val` with given `EndStr`. \n",
    "Let's see it in action with `style` column, I will provide 2 `EndStr` this time as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'EndCmp(style, \"ck\", \"up\")' -c style beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 is returned for `Cup` and `Pack` that ends with given pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`SubCmp(Val, SubStr [, SubStr ...])`**: Compares one or more substring `SubStr` with with any part of `Val`. All the comparisons are case sensitive.\n",
    "\n",
    "* Returns 1 if there is a match, 0 otherwise.\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* Each `SubStr` is a string constant that specifies the substring to match.\n",
    "\n",
    "I will provide \"Noodle\" as `SubStr` for `variety` column, to detect the ramen name which contains \"Noodle\"(case sensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'SubCmp(variety, \"Noodle\")' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will provide 2 strings, \"Noodle\" and \"Spic\"(to match both \"Spicy\" and \"Spice\") to extract names which contains **EITHER** of the words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'SubCmp(variety, \"Noodle\", \"Spic\")' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`SubCmpAll(Val, SubStr [, SubStr ...])`**:Same as `SubCmp()`, except when multiple `SubStr` are provided, it will return 1 only if `Val` contains every single one of `SubStr`.\n",
    "\n",
    "We'll provide \"Noodle\" and \"Spic\" to be compared with `variety` column. This time though it'll return 1 only if `variety` contains **BOTH** \"Noodle\" and \"Spic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'SubCmpAll(variety, \"Noodle\", \"Spic\")' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MixedCmp(Val, SubStr, Typ [, SubStr, Typ ...])`**: You can see this function as more versatile version of `BegCmp`, `EndCmp`, and `SubCmp`. Given `Val`, you'll provide `SubStr` and `Typ` which is one of the followings:\n",
    "* `BEG` - Match with the head of `Val`.\n",
    "* `END` - Match with the tail of `Val`.\n",
    "* `SUB` - Match with any part of `Val`.\n",
    "\n",
    "Note when provided more than 2 `SubStr`, this function will return 1 for matching with **EITHER** of the provided `SubStr`'s pattern. This will be demonstrated at **`SUB`** section later.\n",
    "\n",
    "* `BEG`<br>\n",
    "Let's start with `BEG`. We will use `style` column, and give `C` as `SubStr` to get `style` that begin with \"C\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'MixedCmp(style, \"C\", BEG)' -c style beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `END`<br>\n",
    "\n",
    "Next I will provide `ck` as `SubStr`, and `END` as `Typ` to extract record with style which end with \"ck\" (Pack type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'MixedCmp(style, \"ck\", END)' -c style beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `SUB`<br>\n",
    "Lastly, I will provide \"Noodle\" and \"Spic\" to match with `variety` column as `Val` to extract records that contains EITHER of these strings.\n",
    "Since we're looking for substring match in any position of `variety`, `SUB` will be the `Typ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'MixedCmp(variety, \"Noodle\", SUB, \"Spic\", SUB)' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MixedCmpAll(Val, SubStr, Typ [, SubStr, Typ ...])`**: Same as `MixedCmp()` function above, except when provided more than 2 `SubStr`s, this will return 1 only when all of the `SubStr` are found in `Val` string.\n",
    "You'll provide `SubStr` and `Typ` which is:\n",
    "* `BEG` - Match with the head of Val.\n",
    "* `END` - Match with the tail of Val.\n",
    "* `SUB` - Match with any part of Val.\n",
    "\n",
    "We will demonstrate it using **`SUB`**, with `variety` column.\n",
    "This should only return 1 for the record that contains both \"Noodle\" and \"Spic\" in `variety` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'MixedCmpAll(variety, \"Noodle\", SUB, \"Spic\", SUB)' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Contain(Val, SubStrs)`**: Compares the substrings in `SubStrs` with any part of Val. All the comparisons are case sensitive.\n",
    "\n",
    "* Returns 1 if there is a match, 0 otherwise.\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* `SubStrs` is a string constant that specifies what substrings to match. It is a comma-newline separated list of literal substrings of the form “`SubStr1,[\\r]\\nSubStr2...`”.\n",
    "\n",
    "Let's test this function by providing \"Noodle\" and \"Spic\" as `SubStrs`, and `variety` as `Val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'contain(variety, \"Noodle,\\nSpic\")' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ContainAll(Val, SubStrs)`**:Compares the substrings in SubStrs with any part of Val. All the comparisons are case sensitive.\n",
    "\n",
    "* Returns 1 if all the substrings match, 0 otherwise.\n",
    "* Val can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* SubStrs is a string constant that specifies what substrings to match. It is a comma-newline separated list of literal substrings of the form “`SubStr1,[\\r]\\nSubStr2...`”.\n",
    "\n",
    "Same as `Contain()`, except that when provided with multiple `SubStrs`, it'll return 1 only if all the patterns are present in `Val`. \n",
    "Using `variety` column with values of \"Noodle\" and \"Spic\" again, we'll see that only record with **BOTH** words present in thier `variety` column will have 1 as return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:beginWith' 'ContainAll(variety, \"Noodle,\\nSpic\")' -c variety beginWith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 2 examples below, we'll be using data from an airline online ticket search, which looks like below.\n",
    "\n",
    "ticket|\n",
    "-----|\n",
    "From=ISGTo=OKADate=20150904Class=Y\n",
    "From=OKATo=ITMDate=20150426Class=Y\n",
    "From=ISGTo=OKADate=20150406Class=Y\n",
    "From=ITMTo=FUKDate=20151016Class=Y\n",
    "From=HNDTo=KOJDate=20171112Class=Y\n",
    "From=NGik0To=OKADate=20150425Class=1\n",
    "From=HNDTo=ITMDate=20151113Class=S\n",
    "From=NGOTo=SPKDate=20160528Class=S\n",
    "From=SPKTo=NGODate=20160207Class=S\n",
    "From=OKATo=nG0ODate=20150425Class=3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**`PatCmp(Val, Pattern [, AtrLst])`**:Compares a generic wildcard pattern with Val.\n",
    "\n",
    "* Returns 1 if it matches, 0 otherwise. `Pattern` must match the _entire_ `Val` to be successful.\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* `Pattern` is a string constant that specifies the pattern to match. It is a simple wildcard pattern containing just '*' (matches any number of bytes) and ‘?’ (matches any 1 byte) only; literal ‘*’, ‘?’ and ‘\\’ in the pattern must be ‘\\’ escaped.\n",
    "* Optional `AtrLst` is a list of `|` separated attributes containing:\n",
    "    * `ncas` - Perform a case insensitive match (default is case sensitive). For ASCII data only.\n",
    "\n",
    "On the example below, we'll use wildcard to look for record whose Class is equal to \"Y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline=\"data/aq_pp/airline_sample.csv\"\n",
    "aq_pp -f,+1 $airline -d S:ticket -eval 'is:contains' 'PatCmp(ticket, \"From=*To=*Date=*Class=Y\")' -c ticket contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RxCmp(Val, Pattern [, AtrLst])`**:Compares a string with a regular expression.\n",
    "\n",
    "* Returns 1 if they match, 0 otherwise. `Pattern` only needs to match a subpart of `Val` to be successful.\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* `Pattern` is a string constant that specifies the regular expression to match.\n",
    "* Optional `AtrLst` is a list of `|` separated regular expression attributes.\n",
    "\n",
    "Similar to `RxPat()`, except this uses regex pattern as pattern. Again getting records with Class=Y, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $airline -d S:ticket -eval 'is:contains' 'PatCmp(ticket, \"Class=Y\", pcre)' -c ticket contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`NumCmp(Val1, Val2, Delta)`**:Tests if Val1 and Val2 are within Delta of each other - i.e., whether `Abs(Val1 - Val2) <= Delta`.\n",
    "\n",
    "* Returns 1 if true, 0 otherwise.\n",
    "* `Val1`, `Val2` and `Delta` can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "* `Delta` should be greater than or equal to zero.\n",
    "\n",
    "We'll use following dataset with year, month and day column.\n",
    "\n",
    "year|month|day\n",
    "----|----|---|\n",
    "2015|04|03\n",
    "2015|08|08\n",
    "2015|08|23\n",
    "2015|12|28\n",
    "2016|03|21\n",
    "2016|04|11\n",
    "2016|05|02\n",
    "2016|05|15\n",
    "2016|11|02\n",
    "2016|11|04\n",
    "2016|12|04\n",
    "2017|04|26\n",
    "2017|05|15\n",
    "2017|10|23\n",
    "2017|12|18\n",
    "2018|02|21\n",
    "2018|08|07\n",
    "2018|08|07\n",
    "2018|10|05\n",
    "2018|12|03\n",
    "\n",
    "We will calculate the difference between `month` and `date`, then compare that to our `delta` which is equal to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forth_dim=\"data/aq_pp/year_month_date.csv\"\n",
    "aq_pp -f,+1 $forth_dim -d I:year I:month I:day -eval 'is:delta' 'abs(month - day)' -eval 'is:isWithin' 'NumCmp(month, day, 8)' -c ~year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the rows whose delta value is greater than 8, isWithin's value is 0, and vise versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extract_code'></a>\n",
    "### Data extraction and encode / decode Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`SubStr(Val, Start [, Length])`**: Returns a substring of a string.\n",
    "\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* `Start` is the starting position (zero-based) of the substring in `Val`. It can be a numeric column’s name, a number, or an expression that evaluates to a number.\n",
    "     * If `Start` is negative, the length of `Val` will be added to it. If it is still negative, 0 will be used.(Think of it as a pythonic way of indexing the string from backwards)\n",
    "* Optional `Length` specifies the length of the substring in `Val`. It can be a numeric column’s name, a number, or an expression that evaluates to a number.\n",
    "    * Max length is length of `Val` minus `Start`.\n",
    "    * If `Length` is not specified, max length is assumed.\n",
    "    * If `Length` is negative, max length will be added to it. If it is still negative, 0 will be used.\n",
    "\n",
    "For this example, to keep things simple we'll use a file containing 2 row, one with numeric string and the other with good old \"Hello World\", which looks like below.\n",
    "\n",
    "\n",
    "simple_str|\n",
    "---|\n",
    "0123456789\n",
    "Hello World\n",
    "\n",
    "starting from zero as `Val`, and will extract substring at index 3 ~ last index. We can do this like following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define the filename\n",
    "subStr=\"data/aq_pp/substr.csv\"\n",
    "aq_pp -f,+1 $subStr -d s:val_str -eval 's:subStr' 'SubStr(val_str, 3)' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, string from 3rd index (counting from zero) are extracted as substring. <br>\n",
    "\n",
    "* `Length`<br>\n",
    "Providing this argument will allow users to specify the length of **extracted substring**. Note that this is NOT the ending index of the substring. \n",
    "For example, in order to extract substring at index 3 ~ 7 in the original `Val` string, we'd need to provide `3` as `Start` and `5` as `Length`, since the substring extracted will be the length of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $subStr -d s:val_str -eval 's:subStr' 'SubStr(val_str, 3, 5)' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Negative Index**<br>\n",
    "Users can specify index from right side of the `Val` string, by using negative indexing (Similar to python's string).\n",
    "For example, say we'd like to extract the word \"World\" using the negative index. Letter \"W\" is the 5th character from the right side of the string, so we'll provide `-5` as `Start`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d s:val_str -eval 's:subStr' 'SubStr(val_str, -5)' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Length` argument can also be negative number. Let's provide `-2` as `Length` parameter, and `0` for `Start`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $subStr -d s:val_str -eval 's:subStr' 'SubStr(val_str, 0, -2)' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works exactly as the reverse ending indexing, such that we've extracted substring that ends before the 2nd character from right side of the original string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`StrIndex(Val, Str [, AtrLst])`**: Returns the position (zero-based) of the first occurrence of `Str` in `Val` or -1 if it is not found.\n",
    "\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* `Str` is the value to find within `Val`. It can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* Optional `AtrLst` is a list of `|` separated attributes containing:\n",
    "    * `ncas` - Perform a case insensitive match (default is case sensitive). For ASCII data only.\n",
    "    * `back` - Search backwards from the end of `Val`.\n",
    "\n",
    "Let's check this out with the ramen dataset. We will provide `variety` column as `Val`, and \"Noodle\" as string to get the index of the string in `Val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:isAt' 'StrIndex(variety, \"Noodle\")' -c variety isAt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that it is outputting the index number of the given string, counting from left side of the `Val` string.\n",
    "\n",
    "**Attributes**<br>\n",
    "\n",
    "* **`back`**<br>\n",
    "Note that 2rd record (or 3th row) contains 2 occurence of \"Noodle\", and result returns index of 0. This is because `StrIndex()` only returns the first occurence of given string. <br>\n",
    "We can reverse the search from backwards by giving `back` attribute, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:isAt' 'StrIndex(variety, \"Noodle\", back)' -c variety isAt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd record's result is now 52, which is the index of the second occurence of \"Noodle\" string.\n",
    "\n",
    "* **`ncas`**<br>\n",
    "This attribute perform case insensitive search (default is sensitive). \n",
    "We'll provide \"NOODLE\" as `Str` which wouldn't match any of the record this time, as well as `ncas` for attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'is:isAt' 'StrIndex(variety, \"NOODLE\", ncas)' -c variety isAt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RxMap(Val, MapFrom [, Col, MapTo ...] [, AtrLst])`**: Extracts substrings from a string based on a `MapFrom` expression and place the results in columns based on `MapTo` expressions.\n",
    "\n",
    "* Returns 1 if successful or 0 otherwise. MapFrom only needs to match a subpart of `Val` to be successful.\n",
    "\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "\n",
    "* `MapFrom` is a string constant that specifies the regular expression to match. The expression should contain subexpressions for substring extractions.\n",
    "\n",
    "* The `Col` and `MapTo` pairs define how to save the results. Col is the column to put the result in. It must be of string type. `MapTo` is a string constant that defines how to render the result. It has the form:\n",
    "\n",
    "Optional AtrLst is a list of | separated regular expression attributes.\n",
    "\n",
    "Let's start with simple example. We'll have a address column, filled with fake addresses. And we'd like to extract ZIP code. Data look like below.\n",
    "\n",
    "<a id='fake_address_data'></a>\n",
    "**Fake Address Dataset**\n",
    "\n",
    "\n",
    "fake_address|\n",
    "-----|\n",
    "06060 Cruz Loop Suite 043, Randyberg, WA 82176\n",
    "11919 Wells Field Suite 087, East Dianaport, AL 96554\n",
    "92586 Ferguson Inlet, Port Natalieview, HI 90811\n",
    "836 Myers Road, South Cynthia, TN 70598\n",
    "Unit 2992 Box 3756, DPO AE 65985\n",
    "75721 Jo Bypass, Lake Kaitlin, FL 74395\n",
    "9964 Justin Cliffs Apt. 446, Elizabethstad, MN 58843\n",
    "499 Anderson Ridge, Pattersonton, TN 09233\n",
    "USNS Harris, FPO AE 17643\n",
    "741 Denise Motorway Suite 930, Desireeland, DC 76580\n",
    "\n",
    "We will extract states and zip code from the address using regex. \n",
    "An expression `[A-Z]{2} [0-9]{5}` is provided as `MapFrom` to extract 2 capital alphabet character, followed by whitespace and 5 digit number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file path and column spec\n",
    "fake_addrs=\"data/aq_pp/fake_addrs.csv\"\n",
    "aq_pp -f,+1 $fake_addrs -d S:address -eval S:State_zip '\"96828 HI\"' -eval - 'RxMap(address, \"[A-Z]{2}\\s[0-9]{5}\", State_zip, \"%%0%%\", pcre)' -c State_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`PatMap(Val, MapFrom [, Col, MapTo ...] [, AtrLst])`**:extract substring from `Val` based on `MapFrom` pattern, and map to `Col` based on `MapTo` pattern.\n",
    "\n",
    "This function uses [RT MapFrom](http://auriq.com/documentation/source/reference/manpages/aq_pp.html?highlight=pcre#rt-mapfrom-syntax) expression instead of regex for `MapFrom` value. \n",
    "Let's keep things simple, and extract the zip code only this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $fake_addrs -d S:address -eval S:Zip '\"96828 HI\"' -eval - 'PatMap(address, \"%*%%ZIP:@n:5-5%%%*\", Zip, \"%%ZIP%%\")' -c Zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapFrom expressiosn `%*%%ZIP:@n:5-5%%%*` was used here. \n",
    "\n",
    "- `%*`: represents any numbers of any characters\n",
    "- `%%VarName%%`: variable name of your choice, surrounded by double percent signs\n",
    "- `:`: works as a separator for different attributes to specify the pattern to store in the variable\n",
    "- `@n`: where character after @ represents class type / character type, and here `n` is for numbers.\n",
    "- `5-5`: represents the min and max numbers of characters to match, and here we'd like to extract exactly 5 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`KeyEnc(Col, [, Col ...])`**: Encodes columns of various types into a single string.\n",
    "\n",
    "* Returns a string key. The key is binary, do not try to interpret or modify it.\n",
    "* `Col` are the columns to encode into the key.\n",
    "\n",
    "This feature comes in handy when you'd like to create one composite key column out of multiple columns. Let's create a composite key from `review`, `brand` and `variety`.\n",
    "\n",
    "Here are the selected columns of the data to be encoded.\n",
    "\n",
    "Review|Brand|Country|\n",
    "---|---|---|\n",
    "2580|New Touch|Japan|\n",
    "2579|Just Way|Taiwan|\n",
    "2578|Nissin|USA|\n",
    "2577|Wei Lih|Taiwan|\n",
    "2576|Ching's Secret|India|\n",
    "2575|Samyang Foods|South Korea|\n",
    "2574|Acecook|Japan|\n",
    "2573|Ikeda Shoku|Japan|\n",
    "2572|Ripe'n'Dry|Japan|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 's:key' 'KeyEnc(reviewID, brand, country)' -c key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`KeyDec(Key, Col|\"ColType\" [, Col|\"ColType\" ...])`**: Decodes a key previously encoded by KeyEnc() and place the resulting components in the given columns.\n",
    "\n",
    "* Returns 1 if successful. A failure is considered a processing error. There is no failure return value.\n",
    "* `Key` is the previously encoded value. It can be a string column’s name, a string constant or an expression that evaluates to a string.\n",
    "* Each `Col` or `ColType` specifies a components in the key.\n",
    "    * If a column is given, a component matching the column’s type is expected; the extracted value will be placed in the given column.\n",
    "    * If a column type string is given, a component matching this type is expected, but the extracted value will not be saved.\n",
    "* The components must be given in the same order as in the encoding call.\n",
    "\n",
    "For demonstration purpose, we will encode the record first on the first line, and pipe its output into the second `aq_pp` command on the second line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 's:key' 'KeyEnc(reviewID, brand, country)' -c key | \\\n",
    "aq_pp -f,+1 - -d s:key -eval I:dec_ID '100' -eval S:dec_brand '\"prada\"' -eval S:dec_country '\"South America\"' \\\n",
    "-eval - 'KeyDec(key, dec_ID, dec_brand, dec_country)' -c dec_ID dec_brand dec_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1st line encodes the 3 columns into one string column named `key`, then outputs only that column.\n",
    "* 2nd line get the key from the first `aq_pp` command, then set up destination columns to map the decoded keys.\n",
    "* 3rd line decodes and map the key on the destination columns, and output the 3 columns.\n",
    "\n",
    "You can verify that the content of output column does match the original column's contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ClipStr(Val, ClipSpec)`**:Returns a substring of a string, based on `clipSpec`.\n",
    "\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "\n",
    "* `ClipSpec` is a string constant that specifies how to clip the substring from the source. It is a sequence of individual clip elements separated by “;”:<br>\n",
    "Each clip elements specifies either the starting or trailing portion of the source string `Val`. Below are some of the commonly used ones.\n",
    "    - `Num`: number of bytes / Separators (`Sep`) to clip\n",
    "    - `Dir`: direction to clip the string, `>`:left to right, `<`: right to left.\n",
    "    - `Sep`: Single byte separator character. Substring that are up to the `Num` of `Sep` character will be clipped.\n",
    "\n",
    "Let's take a look at simple examples.\n",
    "\n",
    "We'll use a list of web URLs as data for next few example. It is a single column list with web URL strings.<br>\n",
    "Here are what the URL data looks like.\n",
    "\n",
    "URL|\n",
    "-----|\n",
    "https://duckduckgo.com/?q=is+duckduckgo+safe&t=h_&ia=web|\n",
    "https://www.google.com/search?client=ubuntu&channel=fs&q=hello+world&ie=utf-8&oe=utf-8|\n",
    "http://auriq.com/documentation/search.html?q=emod&check_keywords=yes&area=default|\n",
    "\n",
    "First, let's say you'd like to extract the first 5 characters of the URL. We can specify `ClipSpec` as `5>` where \n",
    "- `Num`: `5` - specifying the numbers of characters to extract.\n",
    "- `Dir`: `>` - specifying the direction of extraction, in this case from left to right.\n",
    "\n",
    "val_str column will be provided as `Val`, and the result will be on `subStr` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning new data file name\n",
    "urls=\"data/aq_pp/clipstr.csv\"\n",
    "aq_pp -f,+1 $urls -d s:val_str -eval 's:subStr' 'ClipStr(val_str, \"5>\")' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`Sep`**<br>\n",
    "Now what if we would like to extract string up until domain name from the URLs? We can do this using `Sep` attributes. <br>\n",
    "We will extract everything up until the third `/` character in the URLs, by specifying `/` as `Sep`, and give `Num` three.\n",
    "Note that the `Sep` is inclusive, therefore the extracted string will include the `Sep` as their last character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $urls -d s:val_str -eval 's:subStr' 'ClipStr(val_str, \"3>/\")' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Different Direction**<br>\n",
    "We can also clip the string from right side. In this example we'll clip the very last portion of the URL, by providing `/` as `Sep` and `<` as `Dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $urls -d s:val_str -eval 's:subStr' 'ClipStr(val_str, \"2</\")' -c  val_str SubStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`QryDec(Val, [, AtrLst], Col, KeyName [, AtrLst] [, Col, KeyName [, AtrLst] ...])`:**<br>\n",
    "Given query string from URL as `Val`, extracts the values of selected [query parameters](https://en.wikipedia.org/wiki/Query_string) and place the results in columns, as well as return number of parameters extracted.\n",
    "\n",
    "`AtrLst` are used to specify extraction behaviour, such as \n",
    "- `beg`: specifying letter to begin extraction at\n",
    "- `dec`: number of times to perform decoding after extraction\n",
    "\n",
    "There are [more attributes available](http://auriq.com/documentation/source/reference/manpages/aq-emod.html?highlight=emod#qrydec), but we'll use `beg` and set it to `?` in order to focus on string after `?` character in the URLs. (Usually query strings are included after `?` character in URLs).\n",
    "We will extract the queries, and store the result (1 or 0) in e_num column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $urls -d S:URL S:result -eval 'I:e_num' 0 -eval e_num 'QryDec(URL, \"beg=?\", result, \"q\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`UrlEnc(Val)`**: URL-encode a string.\n",
    "\n",
    "* Returns the encoded result.\n",
    "* `Val` is the string to encoded. It can be a string column’s name, a string constant or an expression that evaluates to a string.\n",
    "\n",
    "We'll encode the URLs, and store the result on `encoded` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $urls -d s:val_str -eval 's:encoded' 'UrlEnc(val_str)' -c encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`UrlDec(Val)`**: Decodes an URL-encoded string.\n",
    "\n",
    "* Returns the decoded result.\n",
    "* `Val` is an URL-encoded string. It can be a string column’s name, a string constant or an expression that evaluates to a string.\n",
    "\n",
    "We'll first encode the URLs like done so in previous example using `UrlEnc()`, then pass the result to another `aq_pp` command using pipe, then decode the result using `UrlDec()`. The final result will be stored and outputted in decoded_url column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $urls -d s:val_str -eval 's:encoded' 'UrlEnc(val_str)' -c encoded | \\\n",
    "aq_pp -f,+1 - -d s:encoded -eval 's:decoded_url' 'UrlDec(encoded)' -c decoded_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the decoded URLs are identical to the original URLs before encoding was applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Base64Enc(Val)`**: Base64-encode a string.\n",
    "\n",
    "* Returns the encoded result.\n",
    "* ``Val`` is the string to encode.\n",
    "    * It can be a string column's name, a string constant\n",
    "    * or an expression that evaluates to a string.\n",
    "\n",
    "Using the ramen data, we'll encode the `country` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'S:encoded64' 'Base64Enc(country)' -c country encoded64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Base64Dec(Val)`**: Decodes a base64-encoded string.\n",
    "\n",
    "* Returns the decoded result.There is no integrity check. Portions of `Val` that is not base64-encoded are simply skipped. As a result, the function may return a blank string.\n",
    "\n",
    "* `Val` is a base64-encoded string. It can be a string column's name, a string constant or an expression that evaluates to a string.\n",
    "\n",
    "We'll demonstrate it by first encoding country column and place the result on encoded64 column. On second line we will decode that column to compare with the original country column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 'S:encoded64' 'Base64Enc(country)' -c country encoded64 | \\\n",
    "aq_pp -f,+1 - -d s:country s:encoded64 -eval 's:decoded64' 'Base64Dec(encoded64)' -c country decoded64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe that decoded country matches the original column contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conversion'></a>\n",
    "### General Data Conversion Functions\n",
    "\n",
    "There are several data conversion function that convert data into other types, such as following:\n",
    "- `ToIP(Val)`: IP type\n",
    "- `ToS(Val)`: String type\n",
    "- `ToI(Val)`: Integer type\n",
    "- `ToF(Val)`: Float type\n",
    "\n",
    "Each of these takes `Val` as argument, and output the data as a corresponding data types.\n",
    "For concrete examples of the functions, refer to Data Conversion section in `aq_pp -eval` notebook.\n",
    "\n",
    "Other 4 functions are related to manipulating string values. Let's take a look at each of them.\n",
    "\n",
    "\n",
    "**`ToUpper(Val), ToLower(Val)`**: Returns the upper or lower case string representation of `Val`.\n",
    "\n",
    "- For ASCII strings only. May corrupt multibyte character strings.\n",
    "- `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "\n",
    "We'll convert the contents of `style` column in the Ramen dataset into upper case letters. \n",
    "`ToLower(Val)` can be used in a same manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 's:upper' 'ToUpper(style)' -c style upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**`MaskStr(Val)`**: Irreversibly masks (or obfuscates) a string value. The result should be nearly as unique as the original (the probability of two different values having the same masked value is extremely small).\n",
    "\n",
    "* `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "* The length of the result may be the same or longer than the original.\n",
    "\n",
    "Let's apply this function to the `style` column as well. You can observe that same original value are masked into same string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $file -d $cols -eval 's:masked' 'MaskStr(style)' -c style masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RxReplace(Val, RepFrom, Col, RepTo [, AtrLst])`**: Replaces the first or all occurrences of a substring in `Val` matching expression `RepFrom` with expression `RepTo` and place the result in `Col`.\n",
    "\n",
    "- Returns the number of replacements performed or 0 if there is no match.\n",
    "\n",
    "- `Val` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "\n",
    "- `RepFrom` is a string constant that specifies the regular expression to match. Substring(s) matching this expression will be replaced. The expression can contain subexpressions that can be referenced in RepTo.\n",
    "\n",
    "- `Col` is the column to put the result in. It must be of string type.\n",
    "\n",
    "Again we will use fake address dataset. \n",
    "\n",
    "**Fake Address Dataset**\n",
    "\n",
    "\n",
    "fake_address|\n",
    "-----|\n",
    "06060 Cruz Loop Suite 043, Randyberg, WA 82176\n",
    "11919 Wells Field Suite 087, East Dianaport, AL 96554\n",
    "92586 Ferguson Inlet, Port Natalieview, HI 90811\n",
    "836 Myers Road, South Cynthia, TN 70598\n",
    "Unit 2992 Box 3756, DPO AE 65985\n",
    "75721 Jo Bypass, Lake Kaitlin, FL 74395\n",
    "9964 Justin Cliffs Apt. 446, Elizabethstad, MN 58843\n",
    "499 Anderson Ridge, Pattersonton, TN 09233\n",
    "USNS Harris, FPO AE 17643\n",
    "741 Denise Motorway Suite 930, Desireeland, DC 76580\n",
    "\n",
    "In the example below, we will do 2 things.\n",
    "1. extract State and Zip code from `address` column, then assign it to new column called `State_Zip` in a format of `State: WA, Zip: 82176`. \n",
    "2. store the numbers of replacements performed in a row in an integer column `num_rep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $fake_addrs -d S:address \\\n",
    "    -eval 's:replaced' '\"SZ\"' -eval 'i:num_rep' '0' \\\n",
    "    -eval num_rep 'RxReplace(address, \"([A-Z]{2})\\s([0-9]{5})\", replaced, \"STATE: %%1%%, ZIP: %%2%%\", pcre)' -c replaced num_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1st line deals with input spec\n",
    "* 2nd line creates columns to store results.\n",
    "* 3rd line apply `RxReplace()` to `address` column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RxRep(Val, RepFrom, RepTo [, AtrLst])`**: The same as RxReplace() except that it returns the result string directly (for this reason, it does not have RxReplace()‘s Col argument).\n",
    "\n",
    "Let's apply this to same column as above, but this time without numbers of replacement performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp -f,+1 $fake_addrs -d S:address -eval 's:replaced' '\"SZ\"' \\\n",
    "    -eval replaced 'RxRep(address, \"([A-Z]{2})\\s([0-9]{5})\", \"STATE: %%1%%, ZIP: %%2%%\", pcre)' -c replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='date_time'></a>\n",
    "### Date/Time conversion Functions\n",
    "\n",
    "**`DateToTime(DateVal, DateFmt)`**, **`GmDateToTime(DateVal, DateFmt)`**: each of them takes string `DateVal`, and return [UNIX time](https://en.wikipedia.org/wiki/Unix_time) in integral, unless otherwise specified. \n",
    "\n",
    "- `DateVal` can be a string column’s name, a string constant, or an expression that evaluates to a string.\n",
    "- `DateFmt` is a string constant that specifies the format of `DateVal`.\n",
    "\n",
    "Example below will convert date time column's value into UNIX time, and store it in new column (`Unix_time`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data=\"data/aq_pp/dates.csv\"\n",
    "aq_pp -f,+1 $date_data -d S:date -eval 'I:Unix_time' 'DateToTime(date, \"%Y.%m.%d\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DateFmt` used in the example above include followings:\n",
    "\n",
    "- (a dot) `.` - represent a single unwanted character (e.g., a separator).\n",
    "- `%Y` - 1-4 digit year.\n",
    "- `%m` - Month in 1-12.\n",
    "- `%d` - Day of month in 1-31.\n",
    "\n",
    "- `%H` or `%I` - hour in 0-23 or 1-12.\n",
    "- `%M` - Minute in 0-59.\n",
    "- `%S` - Second in 0-59.\n",
    "\n",
    "We only covered a simple example, but more attributes are available.\n",
    "For more details, please refer to the [Date/Time conversion - aq-emod](http://auriq.com/documentation/source/reference/manpages/aq-emod.html#date-time-conversion-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`TimeToDate(TimeVal, DateFmt)`**, **`TimeToGmDate(TimeVal, DateFmt)`**: Both functions return the date string corresponding to TimeVal. The result string’s maximum length is 127.\n",
    "\n",
    "- `TimeVal` can be a numeric column’s name, a numeric constant, or an expression that evaluates to a number.\n",
    "- `DateFmt` is a string constant that specifies the format of the output. \n",
    "- Conversion is timezone dependent. It is done using the program’s default timezone. Set the program’s timezone, e.g, via the TZ environment, before execution if necessary.\n",
    "\n",
    "Example below uses a column of Unix time, to be converted to Date format like \"2019-10-21 16:17:56\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Unix_time\",\"Date\"\n",
      "119731017,\"1973-10-17 18:36:57\"\n",
      "1000000000,\"2001-09-09 01:46:40\"\n",
      "1111111111,\"2005-03-18 01:58:31\"\n",
      "2000000000,\"2033-05-18 03:33:20\"\n",
      "2147483647,\"2038-01-19 03:14:07\"\n"
     ]
    }
   ],
   "source": [
    "unix_data=\"data/aq_pp/Unix_time.csv\"\n",
    "aq_pp -f,+1 $unix_data -d I:Unix_time -eval 'S:Date' 'TimeToDate(Unix_time, \"%Y-%m-%d %H:%M:%S\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set timezone by setting the system's timezone. For example in order to set it to Japan, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Unix_time\",\"Date\"\n",
      "119731017,\"1973-10-18 03:36:57\"\n",
      "1000000000,\"2001-09-09 10:46:40\"\n",
      "1111111111,\"2005-03-18 10:58:31\"\n",
      "2000000000,\"2033-05-18 12:33:20\"\n",
      "2147483647,\"2038-01-19 12:14:07\"\n"
     ]
    }
   ],
   "source": [
    "TZ=\"Japan\" aq_pp -f,+1 $unix_data -d I:Unix_time -eval 'S:Date' 'TimeToDate(Unix_time, \"%Y-%m-%d %H:%M:%S\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Dos\n",
    "\n",
    "<a id='character_encoding'></a>\n",
    "* ### Character set encoding conversion Functions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
