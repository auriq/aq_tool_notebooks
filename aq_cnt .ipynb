{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aq_cnt tips and samples\n",
    "\n",
    "This notebook goes over aq_cnt's options and it's sample usages. \n",
    "Based on AQ Tools version: 2.0.1-1.\n",
    "\n",
    "### Prerequisites\n",
    "Users are assumed to be equipped with decent knowledge of\n",
    "- bash commands\n",
    "- aq_pp command\n",
    "- input, column and output spec for aq_tools\n",
    "\n",
    "\n",
    "We'll be going over each options in the `aq_cnt` command and it's use cases. Have the [aq_cnt documentation](http://auriq.com/documentation/source/reference/manpages/aq_cnt.html?highlight=aq_cnt) ready on the side, so you can refer to it whenever needed.\n",
    "We'll start with basic usage of each options, then dive into advanced usage.\n",
    "\n",
    "### Dataset\n",
    "Will be using [amazon customer review dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) dataset.\n",
    "This dataset was collected over few decades since 1995 and 2015, and contains over 130+ million customer reviews.\n",
    "\n",
    "We'll be using files from multilinugal dataset, from several marketplace internationally to have variety in data.\n",
    "\n",
    "\n",
    "### Terminology\n",
    "- Key: in `aq_cnt`, key means each unique value present in arbitrary column. It can be a composite key, where it is a unique combination of values from several columns. \n",
    "\n",
    "### To do\n",
    "#### Basic \n",
    "Concrete version of the examples from documentation manual page. \n",
    "- k\n",
    "- kx\n",
    "- kX\n",
    "- g\n",
    "#### Advanced\n",
    "- k\n",
    "- kx\n",
    "- kX\n",
    "- g\n",
    "\n",
    "Now we're ready, let's get started!\n",
    "\n",
    "**Note**\n",
    "\n",
    "Throughout the tutorial, we'll be using bash variable to represent fileName and column spec to avoid repetition and lengthy commands.\n",
    "They are assigned on cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marketplace\tcustomer_id\treview_id\tproduct_id\tproduct_parent\tproduct_title\tproduct_category\tstar_rating\thelpful_votes\ttotal_votes\tvine\tverified_purchase\treview_headline\treview_body\treview_date\n",
      "US\t23871632\tR31B5MWO3O7O6\tB007IXWKUK\t600633062\tFifty Shades Darker (Fifty Shades, Book 2)\tDigital_Ebook_Purchase\t2.0\t0.0\t0.0\tN\tY\tFifty shades Darker\tWould not recommend this book to anybody! Please do not waste your money. There is no real plot, the chapters are very repetitive and boring. The story is pathetic and predictable.\t2013-05-31\n",
      "US\t10261718\tRZ891DUCUNPMD\tB00BVMXBVG\t940561470\tOrphan Black: Season 1 (Blu-ray)\tVideo DVD\t5.0\t1.0\t1.0\tN\tY\tawesome show\tA fantastic new series.  Tatiana Maslany is one of the best actresses of this generation and was was robbed of an emmy nomination. Add in the Sci Fi mystery and orphan black is really original and not a clone or knockoff.\t2013-08-10\n",
      "UK\t19372562\tR2D1VN26VB52J0\tB005DOL0R0\t359342335\tAmazon Zip Sleeve for 7-Inch Tablets\tPC\t4.0\t0.0\t1.0\tN\tY\tAs I said it seems fine.\tthis seems to be able to protect my kindle it's padded on the inside and fastens but without dropping it or doing something equally daft I can't say how effective it would be. As I said it seems fine.\t2015-06-17\n"
     ]
    }
   ],
   "source": [
    "# setting filename and column spec, and brief look at the dataset\n",
    "file=\"data/reviews.tsv\"\n",
    "colSpec=$(loginf -f,auto $file -o_pp_col -)\n",
    "head $file -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "- `k`\n",
    "- `kx`\n",
    "- `kX`\n",
    "- `-g`\n",
    "\n",
    "### -k\n",
    "`-k KeyName ColName [ColName ...]`\n",
    "This option counts numbers of unique values present in given column(s). \n",
    "`KeyName` specifies the name of the key (or combination of keys, if multiple columns are given).\n",
    "You can pass multiple columns to count composite key.\n",
    "\n",
    "**Single Column**<br>\n",
    "We can use this to count how many unique products are present in the review.\n",
    "`product_id` column is a unique identifier for each product. \n",
    "Setting keyName as `num_products`, and giving `product_id` to colName option like below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"row\",\"num_product\"\n",
      "data/reviews.tsv: Bad field count: byte=2842981+656 rec=5081 field=#15\n",
      "9999,6575\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1,tsv,eok $file -d $colSpec -k num_product product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- `row` is the numbers of total rows processed by the command (in this case the entire dataset)\n",
    "- `num_products`: number of unique values in `product_id` column.\n",
    "\n",
    "**Multiple columns**\n",
    "Let's observe what happens when we provide the `-k` option with multiple columns. This time we'll use a data (`data/multiple_k.txt`) that looks like a table below, which contains marketplace abbreviation and fake product id number.\n",
    "\n",
    "|marketplace|product_id|\n",
    "|---|---|\n",
    "|US|1|\n",
    "|US|2|\n",
    "|US|3|\n",
    "|JP|1|\n",
    "|JP|2|\n",
    "|JP|3|\n",
    "|FR|1|\n",
    "|FR|2|\n",
    "|FR|3|\n",
    "\n",
    "Now unique numbers of `product_id` in the above case would be 3.\n",
    "However numbers of uniue combinations of `product_id` and `marketplace` would be 9. Let's check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"row\",\"num_product\"\n",
      "9,9\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1,sep=\"|\" data/multiple_k.txt -d s:marketplace i:product_id -k num_product marketplace product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also provide more than 2 columns. This will come in handy when counting numbers of records based on composite key(such as combinations of Last name, first name, phone numbers etc).\n",
    "\n",
    "## -kx\n",
    "\n",
    "`-kx[,AtrLst] File KeyName ColName [ColName ...]` <br>\n",
    "While `-k` option counts and displays the numbers of unique values in given column(s), this option displays the actual unique data in the given columns(s). \n",
    "\n",
    "**Be wary of syntactic difference**<br>\n",
    "This options requires the output file name as the first argument.\n",
    "In this sample we'll be using `-` which outputs on stdout(command line window). \n",
    "    \n",
    "**Single Column**<br>\n",
    "As a example, we'll display the all marketplace names contained in `marketplace` column on amazon review dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"marketplace\"\n",
      "data/reviews.tsv: Bad field count: byte=2842981+656 rec=5081 field=#15\n",
      "\"FR\"\n",
      "\"JP\"\n",
      "\"DE\"\n",
      "\"UK\"\n",
      "\"US\"\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1,tsv,eok $file -d $colSpec -kx - country marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at star_rating as well. As we know amazon's star rating ranges from 1~5, so this dataset should also contain all of the numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/reviews.tsv: Bad field count: byte=2842981+656 rec=5081 field=#15\n",
      "\"star_rating\"\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1,tsv,eok $file -d $colSpec -kx - country star_rating | aq_ord -f,+1 - -d i:star_rating -sort star_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Columns**<br>\n",
    "Providing `marketplace` and `star_rating` columns, we can take a look at star_rating's values in each market place. (More technically, it is listing the unique combination of values from `marketplace` and `star_rating`. \n",
    "\n",
    "**Note**: in below example, `aq_ord` is used after piping to order the result, but is out of scope of this sample. Don't worry about it for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/reviews.tsv: Bad field count: byte=2842981+656 rec=5081 field=#15\n",
      "\"marketplace\",\"star\"\n",
      "\"DE\",\"1\"\n",
      "\"DE\",\"2\"\n",
      "\"DE\",\"3\"\n",
      "\"DE\",\"4\"\n",
      "\"DE\",\"5\"\n",
      "\"FR\",\"1\"\n",
      "\"FR\",\"2\"\n",
      "\"FR\",\"3\"\n",
      "\"FR\",\"4\"\n",
      "\"FR\",\"5\"\n",
      "\"JP\",\"1\"\n",
      "\"JP\",\"2\"\n",
      "\"JP\",\"3\"\n",
      "\"JP\",\"4\"\n",
      "\"JP\",\"5\"\n",
      "\"UK\",\"1\"\n",
      "\"UK\",\"2\"\n",
      "\"UK\",\"3\"\n",
      "\"UK\",\"4\"\n",
      "\"UK\",\"5\"\n",
      "\"US\",\"1\"\n",
      "\"US\",\"2\"\n",
      "\"US\",\"3\"\n",
      "\"US\",\"4\"\n",
      "\"US\",\"5\"\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1,tsv,eok $file -d $colSpec -kx - country marketplace star_rating \\\n",
    "| aq_ord -f,+1 - -d s:marketplace s:star -sort marketplace star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here, further update is needed.\n",
    "\n",
    "\n",
    "## Using Groupby with -g option\n",
    "\n",
    "**What is groupby and how does it work?**\n",
    "`-g` allows users to create group in which to count and analize record. For example, users can specify `marketplace` column as a group, and count numbers of reviews within each market place. \n",
    "\n",
    "### Using Groupby with -k\n",
    "\n",
    "\n",
    "#### Passengers per each passenger class\n",
    "\n",
    "We'll use `-g` option to specify Pclass column as group, and within that group `-k` will count number of unique names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pclass\",\"row\",\"head_counts\"\n",
      "1,216,216\n",
      "2,184,184\n",
      "3,487,487\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1 $file -d $colSpec -g Pclass -k head_counts Name | \\\n",
    "aq_ord -f,+1 - -d i:Pclass i:row i:head_counts -sort Pclass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output is in format of <br>\n",
    "```GroupbyCol(Pclass), row, count```\n",
    "\n",
    "#### Passengers per each passenger class and Sex\n",
    "\n",
    "This time using Sex and PClass as the group, counting names belongs to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pclass\",\"Sex\",\"row\",\"head_counts\"\n",
      "1,\"female\",94,94\n",
      "1,\"male\",122,122\n",
      "2,\"female\",76,76\n",
      "2,\"male\",108,108\n",
      "3,\"female\",144,144\n",
      "3,\"male\",343,343\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1 $file -d $colSpec -g Pclass Sex -k head_counts Name | \\\n",
    "aq_ord -f,+1 - -d i:Pclass s:Sex i:row i:head_counts -sort Pclass Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Groupby with -kx\n",
    "\n",
    "**Little Refresher for `-kx` option**\n",
    "\n",
    "display /output actual unique values of the colName to stdout or file. \n",
    "Close to \n",
    "\n",
    "```python\n",
    "df[column].unique()\n",
    "```\n",
    "in python&pandas stack.\n",
    "\n",
    "#### TItle per each passenger class\n",
    "Let's take a look at person's title (Mr., Miss., Master., etc), and display it within the group of passenger class. \n",
    "To that we'll extract title from name column and map it into new column, named title, using `aq_pp`. \n",
    "Feel free to skip to the counting part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pclass\",\"title\"\n",
      "1,\"Major\"\n",
      "1,\"Master\"\n",
      "1,\n",
      "1,\"Miss\"\n",
      "1,\"Mr\"\n",
      "1,\"Mrs\"\n",
      "2,\n",
      "2,\"Master\"\n",
      "2,\"Miss\"\n",
      "2,\"Mr\"\n",
      "2,\"Mrs\"\n",
      "3,\"Mrs\"\n",
      "3,\"Master\"\n",
      "3,\"Miss\"\n",
      "3,\"Mr\"\n"
     ]
    }
   ],
   "source": [
    "# extracting the title from name column\n",
    "aq_pp -f,+1 $file -d $colSpec -mapf,pcre name \"(M(rs?|is{2}|a(s|j).{1,2}r))\" -mapc s:title \"%%1%%\" -c Pclass title | \\\n",
    "\n",
    "### display the titles in each groups.####\n",
    "aq_cnt -f,+1 - -d i:Pclass s:title -g Pclass -kx - title_by_class title | \\\n",
    "\n",
    "aq_ord -f,+1 - -d i:Pclass s:title -sort Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both class 2 and 3 have same passenger titles, but class 1 also has Major. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Groupby with -kX\n",
    "For instance, let's count the numbers of people survived, within each passanger class(`Pclass`) using `-g` to group by Pclass, then apply `-kX` to display frequencies of each unique values in Survived column (0s and 1s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pclass\",\"Survived\",\"count\"\n",
      "2,0,97\n",
      "2,1,87\n",
      "1,0,80\n",
      "1,1,136\n",
      "3,1,119\n",
      "3,0,368\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1 $file -d $colSpec -g Pclass -kX - survivor_by_class Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the format is in\n",
    "\n",
    "`GroupByCol(Pclass), KeyCol(Survived), Count`\n",
    "\n",
    "### Multiple Groupby\n",
    "We can also specify multiple columns as groups to analyze data. \n",
    "\n",
    "Let's take a look at survivor counts in group of Pclass, and sex as well.\n",
    "Groupby Columns will be Pclass and Sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pclass\",\"Sex\",\"survived\",\"count\"\n",
      "1,\"female\",0,3\n",
      "1,\"female\",1,91\n",
      "1,\"male\",0,77\n",
      "1,\"male\",1,45\n",
      "2,\"female\",0,6\n",
      "2,\"female\",1,70\n",
      "2,\"male\",0,91\n",
      "2,\"male\",1,17\n",
      "3,\"female\",0,72\n",
      "3,\"female\",1,72\n",
      "3,\"male\",0,296\n",
      "3,\"male\",1,47\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1 $file -d $colSpec -g Pclass Sex -kX - survivor_by_class_sex survived | \\\n",
    "aq_ord -f,+1 - -d i:Pclass s:Sex i:survived i:count -sort Pclass Sex Survived #-sort,dec survived # ordering the results for visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the grouping structure of Pclass > Sex > Survived. <br>\n",
    "What happends if we'd like to categorize by Sex first, then into Pclasses? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sex\",\"Pclass\",\"survived\",\"count\"\n",
      "\"female\",1,0,3\n",
      "\"female\",1,1,91\n",
      "\"female\",2,0,6\n",
      "\"female\",2,1,70\n",
      "\"female\",3,0,72\n",
      "\"female\",3,1,72\n",
      "\"male\",1,0,77\n",
      "\"male\",1,1,45\n",
      "\"male\",2,0,91\n",
      "\"male\",2,1,17\n",
      "\"male\",3,0,296\n",
      "\"male\",3,1,47\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1 $file -d $colSpec -g Sex Pclass -kX - survivor_by_class_sex survived | \\\n",
    "aq_ord -f,+1 - -d s:Sex i:Pclass i:survived i:count -sort Sex Pclass Survived #-sort,dec survived # ordering the results for visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked by reversing the column names passed into `-g` option. However when you take a closer look at the comparisons<br>\n",
    "of the 2 outputs, you can see that they're essentially the same data, in different order of row and columns.\\\n",
    "\n",
    "\n",
    "### Wait, but can we do this just by providing multiple colNames??\n",
    "\n",
    "Let's see if we can achieve same result from the last example, using Sex and Pclass as group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sex\",\"Pclass\",\"survived\",\"count\"\n",
      "\"female\",1,0,3\n",
      "\"female\",1,1,91\n",
      "\"female\",2,0,6\n",
      "\"female\",2,1,70\n",
      "\"female\",3,0,72\n",
      "\"female\",3,1,72\n",
      "\"male\",1,0,77\n",
      "\"male\",1,1,45\n",
      "\"male\",2,0,91\n",
      "\"male\",2,1,17\n",
      "\"male\",3,0,296\n",
      "\"male\",3,1,47\n"
     ]
    }
   ],
   "source": [
    "aq_cnt -f,+1 $file -d $colSpec -kX - survivor_by_class_sex Sex Pclass survived | \\\n",
    "aq_ord -f,+1 - -d s:Sex i:Pclass i:survived i:count -sort Sex Pclass Survived #-sort,dec survived # ordering the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "As far as I know, you can, but there might exist some things that can only be done through `-g` option.\n",
    "\n",
    "Will be updated in the futuer on this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
